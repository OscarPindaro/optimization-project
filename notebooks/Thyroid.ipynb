{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8717ef5a",
   "metadata": {},
   "source": [
    "# Thyroid Dataset\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169f98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from src.ORCTModel import ORCTModel, predicted_lab, accuracy\n",
    "from src.cluster import HierarchicalLogisticRegression, best_leaf_assignment\n",
    "\n",
    "import operator\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c14f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "name = \"new_thyroid.csv\"\n",
    "DATASET_PATH = os.path.join(\"datasets\", name)\n",
    "df = pd.read_csv(DATASET_PATH, delimiter=\";\", header=0)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "columns = list(df.columns)\n",
    "X = df[columns[:-1]]\n",
    "y = df[columns[-1]]\n",
    "feature_names = columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f471f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1594\n",
      "Shape: (1594, 187)\n",
      "The are 187 columns\n",
      "\n",
      "Distinct values for 'Classes' column\n",
      "2    834\n",
      "0    384\n",
      "1    376\n",
      "Name: Classes, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows: {}\\nShape: {}\".format(len(df), df.shape))\n",
    "print(\"The are {} columns\".format(len(df.columns)))\n",
    "print(\"\\nDistinct values for 'Classes' column\\n{}\\n\".format(df[\"Classes\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2c93d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = y.unique()\n",
    "vals.sort()\n",
    "heights = [len(y[y==x]) for x in vals ]\n",
    "vals = [str(x) for x in vals]\n",
    "plt.bar(vals, heights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e1e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = X.copy()\n",
    "X_std[feature_names] = MinMaxScaler().fit_transform(X[feature_names])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.25, random_state=SEED)\n",
    "index_features = list(range(0, len(feature_names) - 1))\n",
    "index_instances = list(X_train.index)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "classes = y.unique().tolist()\n",
    "classes.sort() # sorted    \n",
    "classes_en = [i for i in range(len(classes))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89490a7",
   "metadata": {},
   "source": [
    "Sample weigthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630a5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = [len(y_train[y_train==x]) for x in classes]\n",
    "total_samples = sum(occurences)\n",
    "sample_weight = np.zeros_like(y_train)\n",
    "for class_index, n_occurr in zip(classes, occurences):\n",
    "    sample_weight[y_train==class_index]=n_occurr\n",
    "sample_weight = sample_weight/total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcd321",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0040ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_leaves = 4\n",
    "n_clusters = n_leaves\n",
    "clustering_estimators = []\n",
    "params = dict(n_clusters=n_clusters, random_state=SEED)\n",
    "kmeans = KMeans(**params)\n",
    "clustering_estimators.append(kmeans)\n",
    "\n",
    "# Spectral clustering not used since it gave looped\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"single\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"ward\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"complete\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"average\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters)\n",
    "birch = Birch(**params)\n",
    "clustering_estimators.append(birch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05bec3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans 0.03071630923835349\n",
      "AgglomerativeClustering 0.0002648202557415631\n",
      "AgglomerativeClustering 0.027214759684686778\n",
      "AgglomerativeClustering 0.005515461053430391\n",
      "AgglomerativeClustering 0.007174716837755318\n",
      "Birch 0.01720381013165665\n",
      "The best estimator is KMeans(n_clusters=4, random_state=1234)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarpindaro/miniconda3/envs/decision_trees/lib/python3.9/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but Birch was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import find_best_estimator\n",
    "\n",
    "for i in range(len(clustering_estimators)):\n",
    "    try:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train, sample_weight=sample_weight.transpose())\n",
    "    except:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train)\n",
    "\n",
    "for estimator in clustering_estimators:\n",
    "    print(estimator.__class__.__name__, homogeneity_score(y_train, estimator.labels_))\n",
    "    \n",
    "best_estimator = find_best_estimator(clustering_estimators, homogeneity_score, y_train)\n",
    "print(\"The best estimator is {}\".format(best_estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef0fcd",
   "metadata": {},
   "source": [
    "## Leaves assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fc0591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the estimator KMeans, the assignment [0, 3, 1, 2] has a score of 0.008101878533974389\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 3, 1, 2] has a score of 0.009629814142041693\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 2, 1, 3] has a score of 0.007623468537665565\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 3, 1, 2] has a score of 0.004451263856176911\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 1, 2, 3] has a score of 0.07395048274034136\n",
      "For the estimator Birch, the assignment [0, 2, 1, 3] has a score of 0.009227622508936797\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import best_leaf_assignment\n",
    "for estimator in clustering_estimators:\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "    print(\"For the estimator {}, the assignment {} has a score of {}\".format(estimator.__class__.__name__,\n",
    "                                                                             assignment, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd1ccd",
   "metadata": {},
   "source": [
    "## Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc0e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cluster import HierarchicalLogisticRegression\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)), n_leaves=n_leaves, prediction_type=\"deterministic\", random_state=0,\n",
    "                                     logistic_params={\"class_weight\": \"balanced\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b9f8e",
   "metadata": {},
   "source": [
    "The clustering algorithm behave like random classifiers. In this case, since there is a strong imbalance, *balanced_accuracy_score* is used to computed the real accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c827029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(n_clusters=4, random_state=1234) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='single', n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='complete', n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='average', n_clusters=4) accuracy:0.1693292806484296\n",
      "Birch(n_clusters=4) accuracy:0.3333333333333333\n",
      "The best was KMeans(n_clusters=4, random_state=1234) with score 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "best = clustering_estimators[0]\n",
    "best_accuracy = 0\n",
    "i = 0\n",
    "for estimator in clustering_estimators:\n",
    "    \"\"\"\n",
    "    print(estimator)\n",
    "    print(np.unique(estimator.labels_))\n",
    "    for un in np.unique(estimator.labels_):\n",
    "        print(len(estimator.labels_[estimator.labels_==un]))\n",
    "    \"\"\"\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                  true_labels=y_train, metric=completeness_score)\n",
    "    HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=estimator.labels_, leaves_assignment=assignment )\n",
    "    accuracy = balanced_accuracy_score( y_test, HLR.predict(X_test.to_numpy()))\n",
    "    print(\"{} accuracy:{}\".format(estimator, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best = clustering_estimators[i]\n",
    "        best_accuracy = accuracy\n",
    "    i +=1\n",
    "print(\"The best was {} with score {}\".format(best, best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "053037f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true labelling has assignment [0, 2, 1, 3] with score 1.0000000000000042\n",
      "Accuracy using true labellling: 0.3650793650793651\n"
     ]
    }
   ],
   "source": [
    "assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=y_train, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "print(\"The true labelling has assignment {} with score {}\".format(assignment, score))\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)),\n",
    "                                     n_leaves=n_leaves, prediction_type=\"deterministic\",\n",
    "                                     random_state=0)\n",
    "HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=y_train, leaves_assignment=assignment)\n",
    "accuracy = balanced_accuracy_score( y_test, HLR.predict(X_test.to_numpy()))\n",
    "print(\"Accuracy using true labellling: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f80e0",
   "metadata": {},
   "source": [
    "## ORCT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_in_NR(model, i):\n",
    "    if i == 4:\n",
    "        return []\n",
    "    elif i == 5:\n",
    "        return [2]\n",
    "    elif i == 6:\n",
    "        return [1]\n",
    "    elif i == 7:\n",
    "        return [1, 3]\n",
    "\n",
    "\n",
    "def B_in_NL(model, i):\n",
    "    if i == 4:\n",
    "        return [1, 2]\n",
    "    elif i == 5:\n",
    "        return [1]\n",
    "    elif i == 6:\n",
    "        return [3]\n",
    "    elif i == 7:\n",
    "        return []\n",
    "\n",
    "\n",
    "def I_k(model, i):\n",
    "    if i == 0:\n",
    "        return I_in_k[0]\n",
    "    elif i == 1:\n",
    "        return I_in_k[1]\n",
    "    elif i == 2:\n",
    "        return I_in_k[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce22c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_in_NL_R = {4: [], 5: [2], 6: [1], 7: [1, 3]}\n",
    "BF_in_NL_L = {4: [1, 2], 5: [1], 6: [3], 7: []}\n",
    "I_in_k = {i: list(df_train[df_train['Classes'] == i].index) for i in range(len(classes))}\n",
    "my_W = {(i, j): 0.5 if i != j else 0 for i in classes_en for j in classes_en}\n",
    "index_instances = list(X_train.index)\n",
    "my_x = {(i, j): df_train.loc[i][j] for i in index_instances for j in index_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1541edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.stack(HLR.coef_).transpose()\n",
    "mu = np.stack(HLR.intercept_)\n",
    "C = HLR.leaf_class_probs_.transpose()\n",
    "# j+1 due to the convention for the branch nodes (numbered from 1)\n",
    "# it's in the form\n",
    "# (0,1) (0,2) (0,3)\n",
    "# (1,1) (1,2) (1,3) and so one\n",
    "init_a = {(i, j + 1): a[i, j] for i in range(len(index_features)) for j in range(3)}\n",
    "# in the form (1) (2) (3)\n",
    "init_mu = {(i + 1): mu[i] for i in range(3)}\n",
    "# shape (n_classes, n_leaves), and leaves are the last 4 numbers of 2^h -1\n",
    "# (0,4) (0,5) (0,6) (0,7)\n",
    "# (1,4) ---\n",
    "init_c = {(i, j + 4): C[i, j] for i in classes_en for j in range(4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26d1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Initializing ordered Set I with a fundamentally unordered data source\n",
      "    (type: set).  This WILL potentially lead to nondeterministic behavior in\n",
      "    Pyomo\n",
      "WARNING: Initializing ordered Set N_B with a fundamentally unordered data\n",
      "    source (type: set).  This WILL potentially lead to nondeterministic\n",
      "    behavior in Pyomo\n"
     ]
    }
   ],
   "source": [
    "model = ORCTModel(I_in_k=I_in_k, I_k_fun=I_k, index_features=index_features, BF_in_NL_R=BF_in_NL_R,\n",
    "                      B_in_NR=B_in_NR, B_in_NL=B_in_NL, error_weights=my_W, x_train=my_x, init_a=init_a,\n",
    "                      init_mu=init_mu, init_C=init_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d647e8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.12.13: \n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.12.13, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:    99390\n",
      "Number of nonzeros in inequality constraint Jacobian.:      252\n",
      "Number of nonzeros in Lagrangian Hessian.............:    28829\n",
      "\n",
      "Error in an AMPL evaluation. Run with \"halt_on_ampl_error yes\" to see details.\n",
      "Error evaluating Jacobian of equality constraints at user provided starting point.\n",
      "  No scaling factors for equality constraints computed!\n",
      "Error in an AMPL evaluation. Run with \"halt_on_ampl_error yes\" to see details.\n",
      "\n",
      "Number of Iterations....: 0\n",
      "\n",
      "Number of objective function evaluations             = 0\n",
      "Number of objective gradient evaluations             = 0\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 1\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.092\n",
      "Total CPU secs in NLP function evaluations           =      0.007\n",
      "\n",
      "EXIT: Invalid number in NLP function or derivative detected.\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot load a SolverResults object with bad status: error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11025/261960248.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mipopt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"~/miniconda3/envs/decision_trees/bin/ipopt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipopt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git_projects/optimization-project/src/ORCTModel.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, exec_path)\u001b[0m\n\u001b[1;32m     76\u001b[0m         opt = SolverFactory('ipopt',\n\u001b[1;32m     77\u001b[0m                             executable=exec_path)  # in executable the directory path of ipopt.exe\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtee\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/opt/base/solvers.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_solutions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                         _model.solutions.load_from(\n\u001b[0m\u001b[1;32m    627\u001b[0m                             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                             \u001b[0mselect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/PyomoModel.py\u001b[0m in \u001b[0;36mload_from\u001b[0;34m(self, results, allow_consistent_values_for_fixed_vars, comparison_tolerance_for_fixed_vars, ignore_invalid_labels, id, delete_symbol_map, clear, default_variable_value, select, ignore_fixed_vars)\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \"an 'aborted' status, but containing a solution\")\n\u001b[1;32m    223\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 raise ValueError(\"Cannot load a SolverResults object \"\n\u001b[0m\u001b[1;32m    225\u001b[0m                                  \u001b[0;34m\"with bad status: %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                                  % str(results.solver.status))\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load a SolverResults object with bad status: error"
     ]
    }
   ],
   "source": [
    "ipopt_path = \"~/miniconda3/envs/decision_trees/bin/ipopt\"\n",
    "model.solve(ipopt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fcf106",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model.extraction_va()\n",
    "\n",
    "\n",
    "labels = predicted_lab(model.model, X_test, val, index_features)\n",
    "a = accuracy(y_test.to_numpy(), labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees",
   "language": "python",
   "name": "decision_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
