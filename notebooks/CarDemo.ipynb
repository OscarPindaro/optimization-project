{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65056311",
   "metadata": {},
   "source": [
    "# Testing Hiercal Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce56a2",
   "metadata": {},
   "source": [
    "## CarDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509007b",
   "metadata": {},
   "source": [
    "### Preprocessing of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b782cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c043b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety Classes\n",
       "0       3      3      2        2         0       0   unacc\n",
       "1       3      3      2        2         0       1   unacc\n",
       "2       3      3      2        2         0       2   unacc\n",
       "3       3      3      2        2         1       0   unacc\n",
       "4       3      3      2        2         1       1   unacc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "DATASET_PATH = os.path.join(\"datasets\", \"car.csv\")\n",
    "names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"Classes\"]\n",
    "car = pd.read_csv(DATASET_PATH, delimiter=\";\", header=0, names=names)\n",
    "car = car.convert_dtypes()\n",
    "TARGET_INDEX = car.shape[1] - 1\n",
    "# dictionary converting ordinal categories to values\n",
    "cost_dict = {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3}\n",
    "doors_dict = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
    "persons_dict = {\"2\": 2, \"4\": 4, \"more\": 5}\n",
    "dimension_dict = {\"small\": 0, \"med\": 1, \"big\": 2}\n",
    "# buying\n",
    "car[\"buying\"] = car[\"buying\"].apply(lambda x: cost_dict[x])\n",
    "car[\"maint\"] = car[\"maint\"].apply(lambda x: cost_dict[x])\n",
    "car[\"doors\"] = car[\"doors\"].apply(lambda x: doors_dict[x])\n",
    "car[\"persons\"] = car[\"persons\"].apply(lambda x: persons_dict[x])\n",
    "car[\"lug_boot\"] = car[\"lug_boot\"].apply(lambda x: dimension_dict[x])\n",
    "car[\"safety\"] = car[\"safety\"].apply(lambda x: cost_dict[x])\n",
    "car.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f08142",
   "metadata": {},
   "source": [
    "Labelling the classes with integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bcbe201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  Classes\n",
       "0       3      3      2        2         0       0        2\n",
       "1       3      3      2        2         0       1        2\n",
       "2       3      3      2        2         0       2        2\n",
       "3       3      3      2        2         1       0        2\n",
       "4       3      3      2        2         1       1        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_encoder = preprocessing.LabelEncoder().fit(car[\"Classes\"])\n",
    "car[\"Classes\"] = classes_encoder.transform(car[\"Classes\"])\n",
    "car.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57cfb0",
   "metadata": {},
   "source": [
    "Apply last transformation to input and extract targets. Then split the dataset into training and test. Training is done with 1 fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0be8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.224745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        buying     maint     doors   persons  lug_boot    safety\n",
       "1710 -1.341641 -1.341641  1.341641  0.267261 -1.224745 -1.224745"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing: we get the columns names of features which have to be standardized\n",
    "feature_names = list(car)[0:-1]\n",
    "\n",
    "car_features = car[feature_names]\n",
    "X_std = car_features.copy()\n",
    "X_std[feature_names] = StandardScaler().fit_transform(car_features)\n",
    "y = car[\"Classes\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.25, random_state=SEED)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "classes = y.unique().tolist()\n",
    "classes.sort() # sorted \n",
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0851a31",
   "metadata": {},
   "source": [
    "Let's visualize class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bd9d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[278, 52, 916, 50]\n"
     ]
    }
   ],
   "source": [
    "vals = y_train.unique()\n",
    "vals.sort()\n",
    "heights = [len(y_train[y_train==x]) for x in vals ]\n",
    "vals = [str(x) for x in vals]\n",
    "plt.bar(vals, heights)\n",
    "plt.show()\n",
    "print(heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684245d",
   "metadata": {},
   "source": [
    "### Hierarchical Logistic Regression\n",
    "The idea is to pre-train a binary classification tree with the same strcture of the ORCT. Then, the values of the parameters are extracted an passed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ec525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cluster import find_best_estimator, best_leaf_assignment, HierarchicalLogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e67bc18",
   "metadata": {},
   "source": [
    "First of all we need to find the best estimator. Different clustering algorithms are used. The one that maximizes **homogeneity** is the one chosen. Other metrics can be used, such as **precision**, **purity** and so on. This metrics have all in common the fact that try to maximize the similarity of the points in a cluster. In fact, **homogeneity** is the property that checks how many sample of the same cluster are in the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b945b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = [len(y_train[y_train==x]) for x in classes]\n",
    "total_samples = sum(occurences)\n",
    "sample_weight = np.zeros_like(y_train)\n",
    "for class_index, n_occurr in zip(classes, occurences):\n",
    "    sample_weight[y_train==class_index]=n_occurr\n",
    "sample_weight = sample_weight/total_samples\n",
    "    \n",
    "\n",
    "\n",
    "clustering_estimators = []\n",
    "params = dict(n_clusters=4, random_state=SEED)\n",
    "kmeans = KMeans(**params)\n",
    "clustering_estimators.append(kmeans)\n",
    "\n",
    "params = dict(n_clusters=4, random_state=SEED, assign_labels=\"discretize\", gamma=1)\n",
    "spectral = SpectralClustering(**params)\n",
    "clustering_estimators.append(spectral)\n",
    "\n",
    "params = dict(n_clusters=4, linkage=\"single\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=4, linkage=\"ward\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=4, linkage=\"complete\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=4, linkage=\"average\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=4)\n",
    "birch = Birch(**params)\n",
    "clustering_estimators.append(birch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc92ef0",
   "metadata": {},
   "source": [
    "Fit every estimator and computes their homogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "693d3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans 0.11250442759726538\n",
      "SpectralClustering 0.25519657855590033\n",
      "AgglomerativeClustering 0.17317075945277882\n",
      "AgglomerativeClustering 0.298780930041104\n",
      "AgglomerativeClustering 0.2465504369372705\n",
      "AgglomerativeClustering 0.2364953708934848\n",
      "Birch 0.25755540689535616\n",
      "The best estimator is AgglomerativeClustering(n_clusters=4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarpindaro/miniconda3/envs/decision_trees/lib/python3.9/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but Birch was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clustering_estimators)):\n",
    "    try:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train, sample_weight=sample_weight)\n",
    "    except:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train)\n",
    "\n",
    "for estimator in clustering_estimators:\n",
    "    print(estimator.__class__.__name__, homogeneity_score(y_train, estimator.labels_))\n",
    "    \n",
    "best_estimator = find_best_estimator(clustering_estimators, homogeneity_score, y_train)\n",
    "print(\"The best estimator is {}\".format(best_estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e224f60",
   "metadata": {},
   "source": [
    "Creation of the HLR. The number of leaves must be a power of 2. In this case, since the classes are 4, the leaves will be set to 4. This regressor also needs to know how many classes will encounter.<br> \n",
    "Since this classifier is a series of logistic regressors, is also possible to pass the parameters that will be used to inizialized every regressor.\n",
    "The clustering performed before is used to create multiple clusters that will be assigned to each leaf of the ORCT. In order to find the best assignment, an exhaustive search is done, an the best assingment is found by maximizing the **completeness score**, which measures how much the element of a class are present in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb1e8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assignment [0, 1, 2, 3] has a score of 0.27184733468256117\n"
     ]
    }
   ],
   "source": [
    "n_leaves = 4\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)), n_leaves=n_leaves, prediction_type=\"deterministic\", random_state=0,\n",
    "                                     logistic_params={\"class_weight\": \"balanced\"})\n",
    "assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=best_estimator.labels_, \n",
    "                                  true_labels=y_train, metric=completeness_score)\n",
    "print(\"The assignment {} has a score of {}\".format(assignment, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8cbda",
   "metadata": {},
   "source": [
    "Now it's time to fit the agent. It needs the labels estimater by the clustering and also the assignment of every clustering to each leaves. This model is also able to predict the class of a given sample and can be scored like every other sklearn classifier. <br>\n",
    "When the classifier is fit, every information about the logistic regressors is computed and is present in the attributes of the HLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ef4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLR = HLR.fit(X_train, y_train, cluster_labels=estimator.labels_, leaves_assignment=assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4907f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy is 0.6805555555555556\n"
     ]
    }
   ],
   "source": [
    "score = HLR.score(X_test.to_numpy(), y_test)\n",
    "print(\"The mean accuracy is {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f8bd836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31690141, 0.07981221, 0.52347418, 0.07981221],\n",
       "       [0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.11618257, 0.        , 0.88381743, 0.        ],\n",
       "       [0.52511416, 0.08219178, 0.3196347 , 0.07305936]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLR.leaf_class_probs_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35acc5c3",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f6aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_in_NR(model, i):\n",
    "    if i==4:\n",
    "        return []\n",
    "    elif i==5:\n",
    "        return [2]\n",
    "    elif i==6:\n",
    "        return [1]\n",
    "    elif i==7:\n",
    "        return [1,3]\n",
    "def B_in_NL(model, i):\n",
    "    if i==4:\n",
    "        return [1,2]\n",
    "    elif i==5:\n",
    "        return [1]\n",
    "    elif i==6:\n",
    "        return [3]\n",
    "    elif i==7:\n",
    "        return []\n",
    "\n",
    "def I_k(model,i):\n",
    "    if i==0:\n",
    "        return I_in_k[0]\n",
    "    elif i==1:\n",
    "        return I_in_k[1]\n",
    "    elif i==2:\n",
    "        return I_in_k[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf2e31",
   "metadata": {},
   "source": [
    "Objects useful to deal with trees (of depth 2) and their topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa682d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_in_NL_R = {4:[],5:[2],6:[1],7:[1,3]}\n",
    "BF_in_NL_L = {4:[1,2],5:[1],6:[3],7:[]}\n",
    "I_in_k = {i : list(df_train[df_train['Classes']== i].index) for i in range(len(classes))}\n",
    "my_W = {(i,j): 0.5 if i != j else 0 for i in classes for j in classes}\n",
    "index_instances = list(X_train.index)\n",
    "index_features = range(len(feature_names))\n",
    "my_x = {(i,j): df_train.loc[i][j] for i in index_instances for j in index_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b75fc3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1429,\n",
       "  962,\n",
       "  232,\n",
       "  418,\n",
       "  1366,\n",
       "  878,\n",
       "  431,\n",
       "  227,\n",
       "  1346,\n",
       "  803,\n",
       "  1093,\n",
       "  1507,\n",
       "  859,\n",
       "  1312,\n",
       "  662,\n",
       "  241,\n",
       "  373,\n",
       "  821,\n",
       "  422,\n",
       "  376,\n",
       "  718,\n",
       "  1153,\n",
       "  995,\n",
       "  1183,\n",
       "  767,\n",
       "  929,\n",
       "  286,\n",
       "  851,\n",
       "  782,\n",
       "  862,\n",
       "  1144,\n",
       "  566,\n",
       "  614,\n",
       "  287,\n",
       "  1711,\n",
       "  880,\n",
       "  428,\n",
       "  889,\n",
       "  1064,\n",
       "  1505,\n",
       "  290,\n",
       "  323,\n",
       "  1558,\n",
       "  268,\n",
       "  1612,\n",
       "  589,\n",
       "  854,\n",
       "  800,\n",
       "  398,\n",
       "  394,\n",
       "  646,\n",
       "  808,\n",
       "  824,\n",
       "  1495,\n",
       "  916,\n",
       "  1117,\n",
       "  367,\n",
       "  260,\n",
       "  881,\n",
       "  317,\n",
       "  917,\n",
       "  772,\n",
       "  1147,\n",
       "  1456,\n",
       "  1171,\n",
       "  1345,\n",
       "  1666,\n",
       "  590,\n",
       "  605,\n",
       "  308,\n",
       "  1525,\n",
       "  1172,\n",
       "  1418,\n",
       "  725,\n",
       "  1118,\n",
       "  742,\n",
       "  400,\n",
       "  1048,\n",
       "  1016,\n",
       "  1477,\n",
       "  403,\n",
       "  1234,\n",
       "  988,\n",
       "  779,\n",
       "  1363,\n",
       "  592,\n",
       "  610,\n",
       "  1321,\n",
       "  551,\n",
       "  1388,\n",
       "  310,\n",
       "  1510,\n",
       "  1120,\n",
       "  1397,\n",
       "  1402,\n",
       "  1096,\n",
       "  292,\n",
       "  1069,\n",
       "  1102,\n",
       "  322,\n",
       "  971,\n",
       "  1469,\n",
       "  283,\n",
       "  578,\n",
       "  1498,\n",
       "  1019,\n",
       "  1094,\n",
       "  799,\n",
       "  833,\n",
       "  401,\n",
       "  335,\n",
       "  1181,\n",
       "  674,\n",
       "  320,\n",
       "  427,\n",
       "  1370,\n",
       "  563,\n",
       "  902,\n",
       "  1040,\n",
       "  1474,\n",
       "  959,\n",
       "  1225,\n",
       "  989,\n",
       "  1073,\n",
       "  259,\n",
       "  1415,\n",
       "  239,\n",
       "  1049,\n",
       "  581,\n",
       "  1343,\n",
       "  691,\n",
       "  419,\n",
       "  421,\n",
       "  1403,\n",
       "  341,\n",
       "  1091,\n",
       "  556,\n",
       "  968,\n",
       "  722,\n",
       "  392,\n",
       "  391,\n",
       "  1361,\n",
       "  1046,\n",
       "  1177,\n",
       "  1052,\n",
       "  607,\n",
       "  242,\n",
       "  890,\n",
       "  349,\n",
       "  1279,\n",
       "  958,\n",
       "  1013,\n",
       "  1660,\n",
       "  416,\n",
       "  1037,\n",
       "  295,\n",
       "  1603,\n",
       "  647,\n",
       "  1364,\n",
       "  835,\n",
       "  296,\n",
       "  983,\n",
       "  1453,\n",
       "  1642,\n",
       "  773,\n",
       "  1399,\n",
       "  1067,\n",
       "  998,\n",
       "  1201,\n",
       "  583,\n",
       "  1483,\n",
       "  698,\n",
       "  751,\n",
       "  695,\n",
       "  701,\n",
       "  1478,\n",
       "  233,\n",
       "  1444,\n",
       "  269,\n",
       "  620,\n",
       "  1445,\n",
       "  997,\n",
       "  1103,\n",
       "  1391,\n",
       "  715,\n",
       "  557,\n",
       "  1376,\n",
       "  1576,\n",
       "  635,\n",
       "  1043,\n",
       "  1024,\n",
       "  700,\n",
       "  1186,\n",
       "  1417,\n",
       "  430,\n",
       "  1585,\n",
       "  1400,\n",
       "  1394,\n",
       "  611,\n",
       "  1126,\n",
       "  617,\n",
       "  1480,\n",
       "  1471,\n",
       "  1070,\n",
       "  665,\n",
       "  1447,\n",
       "  554,\n",
       "  826,\n",
       "  941,\n",
       "  584,\n",
       "  935,\n",
       "  944,\n",
       "  1426,\n",
       "  727,\n",
       "  1414,\n",
       "  1156,\n",
       "  1210,\n",
       "  565,\n",
       "  857,\n",
       "  1442,\n",
       "  970,\n",
       "  863,\n",
       "  943,\n",
       "  1261,\n",
       "  692,\n",
       "  1022,\n",
       "  673,\n",
       "  1288,\n",
       "  1496,\n",
       "  1534,\n",
       "  1015,\n",
       "  368,\n",
       "  314,\n",
       "  887,\n",
       "  1340,\n",
       "  1307,\n",
       "  794,\n",
       "  404,\n",
       "  938,\n",
       "  659,\n",
       "  1319,\n",
       "  932,\n",
       "  1174,\n",
       "  749,\n",
       "  1310,\n",
       "  931,\n",
       "  1337,\n",
       "  365,\n",
       "  377,\n",
       "  754,\n",
       "  1154,\n",
       "  1720,\n",
       "  1693,\n",
       "  713,\n",
       "  1025,\n",
       "  425,\n",
       "  1684,\n",
       "  1630,\n",
       "  340,\n",
       "  311,\n",
       "  911,\n",
       "  374,\n",
       "  806,\n",
       "  1042,\n",
       "  986,\n",
       "  1021,\n",
       "  608,\n",
       "  1105,\n",
       "  619,\n",
       "  371,\n",
       "  908,\n",
       "  745,\n",
       "  743,\n",
       "  293,\n",
       "  1349,\n",
       "  689,\n",
       "  664,\n",
       "  1228],\n",
       " 1: [1667,\n",
       "  1606,\n",
       "  1618,\n",
       "  1561,\n",
       "  1658,\n",
       "  1555,\n",
       "  1289,\n",
       "  1202,\n",
       "  1615,\n",
       "  1213,\n",
       "  1204,\n",
       "  1694,\n",
       "  1559,\n",
       "  1577,\n",
       "  1609,\n",
       "  1699,\n",
       "  1264,\n",
       "  1634,\n",
       "  1231,\n",
       "  1240,\n",
       "  1258,\n",
       "  1294,\n",
       "  1579,\n",
       "  1226,\n",
       "  1604,\n",
       "  1690,\n",
       "  1211,\n",
       "  1663,\n",
       "  1291,\n",
       "  1253,\n",
       "  1285,\n",
       "  1262,\n",
       "  1523,\n",
       "  1537,\n",
       "  1591,\n",
       "  1553,\n",
       "  1582,\n",
       "  1687,\n",
       "  1714,\n",
       "  1588,\n",
       "  1535,\n",
       "  1726,\n",
       "  1636,\n",
       "  1550,\n",
       "  1717,\n",
       "  1235,\n",
       "  1661,\n",
       "  1280,\n",
       "  1267,\n",
       "  1643,\n",
       "  1282,\n",
       "  1586],\n",
       " 2: [1710,\n",
       "  543,\n",
       "  1437,\n",
       "  1416,\n",
       "  690,\n",
       "  675,\n",
       "  828,\n",
       "  731,\n",
       "  796,\n",
       "  147,\n",
       "  758,\n",
       "  507,\n",
       "  60,\n",
       "  1356,\n",
       "  435,\n",
       "  492,\n",
       "  348,\n",
       "  1434,\n",
       "  302,\n",
       "  33,\n",
       "  876,\n",
       "  1590,\n",
       "  375,\n",
       "  793,\n",
       "  1422,\n",
       "  739,\n",
       "  652,\n",
       "  895,\n",
       "  329,\n",
       "  175,\n",
       "  1085,\n",
       "  413,\n",
       "  117,\n",
       "  768,\n",
       "  1719,\n",
       "  586,\n",
       "  750,\n",
       "  1368,\n",
       "  272,\n",
       "  1602,\n",
       "  133,\n",
       "  703,\n",
       "  1056,\n",
       "  1119,\n",
       "  909,\n",
       "  390,\n",
       "  72,\n",
       "  1465,\n",
       "  867,\n",
       "  1384,\n",
       "  1545,\n",
       "  249,\n",
       "  1270,\n",
       "  1301,\n",
       "  1515,\n",
       "  1678,\n",
       "  972,\n",
       "  83,\n",
       "  412,\n",
       "  631,\n",
       "  1440,\n",
       "  6,\n",
       "  1169,\n",
       "  27,\n",
       "  89,\n",
       "  166,\n",
       "  201,\n",
       "  1701,\n",
       "  356,\n",
       "  160,\n",
       "  1350,\n",
       "  298,\n",
       "  801,\n",
       "  122,\n",
       "  118,\n",
       "  170,\n",
       "  71,\n",
       "  99,\n",
       "  868,\n",
       "  790,\n",
       "  1212,\n",
       "  1179,\n",
       "  1686,\n",
       "  1354,\n",
       "  125,\n",
       "  146,\n",
       "  1722,\n",
       "  953,\n",
       "  1446,\n",
       "  599,\n",
       "  143,\n",
       "  789,\n",
       "  353,\n",
       "  215,\n",
       "  458,\n",
       "  1116,\n",
       "  285,\n",
       "  525,\n",
       "  388,\n",
       "  1494,\n",
       "  1423,\n",
       "  726,\n",
       "  1053,\n",
       "  985,\n",
       "  1113,\n",
       "  948,\n",
       "  1170,\n",
       "  17,\n",
       "  1695,\n",
       "  1540,\n",
       "  1314,\n",
       "  277,\n",
       "  1324,\n",
       "  858,\n",
       "  765,\n",
       "  1517,\n",
       "  1725,\n",
       "  544,\n",
       "  1652,\n",
       "  1369,\n",
       "  1681,\n",
       "  169,\n",
       "  685,\n",
       "  661,\n",
       "  1338,\n",
       "  947,\n",
       "  294,\n",
       "  529,\n",
       "  1698,\n",
       "  1250,\n",
       "  221,\n",
       "  205,\n",
       "  1293,\n",
       "  1594,\n",
       "  688,\n",
       "  950,\n",
       "  387,\n",
       "  128,\n",
       "  1317,\n",
       "  973,\n",
       "  470,\n",
       "  839,\n",
       "  519,\n",
       "  13,\n",
       "  207,\n",
       "  760,\n",
       "  420,\n",
       "  1251,\n",
       "  1190,\n",
       "  912,\n",
       "  1629,\n",
       "  536,\n",
       "  1271,\n",
       "  1512,\n",
       "  588,\n",
       "  446,\n",
       "  1459,\n",
       "  226,\n",
       "  112,\n",
       "  495,\n",
       "  696,\n",
       "  869,\n",
       "  1443,\n",
       "  1461,\n",
       "  1476,\n",
       "  681,\n",
       "  899,\n",
       "  1011,\n",
       "  494,\n",
       "  1493,\n",
       "  503,\n",
       "  1357,\n",
       "  264,\n",
       "  58,\n",
       "  423,\n",
       "  1074,\n",
       "  818,\n",
       "  1031,\n",
       "  925,\n",
       "  1104,\n",
       "  100,\n",
       "  576,\n",
       "  369,\n",
       "  813,\n",
       "  1462,\n",
       "  93,\n",
       "  667,\n",
       "  923,\n",
       "  1082,\n",
       "  1003,\n",
       "  1411,\n",
       "  361,\n",
       "  648,\n",
       "  271,\n",
       "  1532,\n",
       "  402,\n",
       "  1497,\n",
       "  1012,\n",
       "  1531,\n",
       "  1290,\n",
       "  2,\n",
       "  522,\n",
       "  40,\n",
       "  225,\n",
       "  650,\n",
       "  1614,\n",
       "  330,\n",
       "  191,\n",
       "  1195,\n",
       "  1635,\n",
       "  248,\n",
       "  261,\n",
       "  1029,\n",
       "  1246,\n",
       "  81,\n",
       "  452,\n",
       "  1331,\n",
       "  137,\n",
       "  964,\n",
       "  534,\n",
       "  505,\n",
       "  449,\n",
       "  111,\n",
       "  1155,\n",
       "  1560,\n",
       "  363,\n",
       "  445,\n",
       "  530,\n",
       "  1479,\n",
       "  378,\n",
       "  1300,\n",
       "  61,\n",
       "  1470,\n",
       "  206,\n",
       "  282,\n",
       "  1706,\n",
       "  29,\n",
       "  1518,\n",
       "  842,\n",
       "  523,\n",
       "  910,\n",
       "  114,\n",
       "  63,\n",
       "  38,\n",
       "  1086,\n",
       "  1581,\n",
       "  499,\n",
       "  1249,\n",
       "  981,\n",
       "  1381,\n",
       "  484,\n",
       "  804,\n",
       "  952,\n",
       "  380,\n",
       "  224,\n",
       "  426,\n",
       "  942,\n",
       "  601,\n",
       "  1000,\n",
       "  1315,\n",
       "  582,\n",
       "  918,\n",
       "  954,\n",
       "  270,\n",
       "  39,\n",
       "  479,\n",
       "  630,\n",
       "  104,\n",
       "  1332,\n",
       "  1716,\n",
       "  831,\n",
       "  1689,\n",
       "  1200,\n",
       "  1569,\n",
       "  1439,\n",
       "  1568,\n",
       "  978,\n",
       "  247,\n",
       "  764,\n",
       "  326,\n",
       "  1622,\n",
       "  1047,\n",
       "  480,\n",
       "  1596,\n",
       "  1386,\n",
       "  1703,\n",
       "  1017,\n",
       "  155,\n",
       "  163,\n",
       "  516,\n",
       "  467,\n",
       "  626,\n",
       "  472,\n",
       "  171,\n",
       "  518,\n",
       "  538,\n",
       "  304,\n",
       "  976,\n",
       "  1023,\n",
       "  670,\n",
       "  864,\n",
       "  819,\n",
       "  1516,\n",
       "  1274,\n",
       "  94,\n",
       "  562,\n",
       "  712,\n",
       "  1001,\n",
       "  883,\n",
       "  1189,\n",
       "  1675,\n",
       "  1595,\n",
       "  756,\n",
       "  1406,\n",
       "  993,\n",
       "  1598,\n",
       "  775,\n",
       "  1,\n",
       "  882,\n",
       "  870,\n",
       "  1627,\n",
       "  258,\n",
       "  1149,\n",
       "  539,\n",
       "  533,\n",
       "  1520,\n",
       "  408,\n",
       "  1269,\n",
       "  461,\n",
       "  176,\n",
       "  7,\n",
       "  655,\n",
       "  1243,\n",
       "  613,\n",
       "  1320,\n",
       "  1377,\n",
       "  735,\n",
       "  609,\n",
       "  555,\n",
       "  1490,\n",
       "  204,\n",
       "  717,\n",
       "  604,\n",
       "  738,\n",
       "  606,\n",
       "  199,\n",
       "  1063,\n",
       "  1221,\n",
       "  845,\n",
       "  1298,\n",
       "  9,\n",
       "  844,\n",
       "  240,\n",
       "  951,\n",
       "  1191,\n",
       "  1413,\n",
       "  1359,\n",
       "  1303,\n",
       "  214,\n",
       "  866,\n",
       "  1438,\n",
       "  1378,\n",
       "  730,\n",
       "  1325,\n",
       "  1351,\n",
       "  816,\n",
       "  115,\n",
       "  1128,\n",
       "  1245,\n",
       "  8,\n",
       "  798,\n",
       "  67,\n",
       "  906,\n",
       "  219,\n",
       "  1054,\n",
       "  1492,\n",
       "  1600,\n",
       "  660,\n",
       "  1080,\n",
       "  732,\n",
       "  1009,\n",
       "  51,\n",
       "  628,\n",
       "  1194,\n",
       "  342,\n",
       "  598,\n",
       "  812,\n",
       "  56,\n",
       "  360,\n",
       "  585,\n",
       "  1395,\n",
       "  410,\n",
       "  185,\n",
       "  769,\n",
       "  186,\n",
       "  509,\n",
       "  131,\n",
       "  591,\n",
       "  159,\n",
       "  783,\n",
       "  1482,\n",
       "  382,\n",
       "  1659,\n",
       "  656,\n",
       "  1557,\n",
       "  1173,\n",
       "  1543,\n",
       "  1527,\n",
       "  245,\n",
       "  1709,\n",
       "  1006,\n",
       "  1084,\n",
       "  297,\n",
       "  597,\n",
       "  267,\n",
       "  1140,\n",
       "  558,\n",
       "  1647,\n",
       "  1656,\n",
       "  1135,\n",
       "  121,\n",
       "  357,\n",
       "  498,\n",
       "  339,\n",
       "  109,\n",
       "  627,\n",
       "  65,\n",
       "  1362,\n",
       "  450,\n",
       "  262,\n",
       "  1161,\n",
       "  1152,\n",
       "  288,\n",
       "  1165,\n",
       "  829,\n",
       "  1353,\n",
       "  1272,\n",
       "  48,\n",
       "  453,\n",
       "  1524,\n",
       "  167,\n",
       "  1653,\n",
       "  1713,\n",
       "  512,\n",
       "  1358,\n",
       "  1088,\n",
       "  792,\n",
       "  975,\n",
       "  457,\n",
       "  807,\n",
       "  1244,\n",
       "  1041,\n",
       "  126,\n",
       "  1365,\n",
       "  1347,\n",
       "  822,\n",
       "  901,\n",
       "  645,\n",
       "  496,\n",
       "  307,\n",
       "  612,\n",
       "  187,\n",
       "  1383,\n",
       "  977,\n",
       "  1071,\n",
       "  1032,\n",
       "  189,\n",
       "  1641,\n",
       "  200,\n",
       "  1095,\n",
       "  138,\n",
       "  19,\n",
       "  278,\n",
       "  194,\n",
       "  1254,\n",
       "  683,\n",
       "  511,\n",
       "  945,\n",
       "  1628,\n",
       "  1570,\n",
       "  699,\n",
       "  741,\n",
       "  491,\n",
       "  96,\n",
       "  1036,\n",
       "  203,\n",
       "  158,\n",
       "  26,\n",
       "  145,\n",
       "  70,\n",
       "  157,\n",
       "  318,\n",
       "  325,\n",
       "  476,\n",
       "  1683,\n",
       "  36,\n",
       "  64,\n",
       "  1296,\n",
       "  37,\n",
       "  252,\n",
       "  1146,\n",
       "  195,\n",
       "  1044,\n",
       "  75,\n",
       "  639,\n",
       "  843,\n",
       "  153,\n",
       "  1193,\n",
       "  733,\n",
       "  209,\n",
       "  708,\n",
       "  679,\n",
       "  1546,\n",
       "  86,\n",
       "  52,\n",
       "  1002,\n",
       "  571,\n",
       "  1419,\n",
       "  393,\n",
       "  777,\n",
       "  1101,\n",
       "  1344,\n",
       "  437,\n",
       "  776,\n",
       "  1139,\n",
       "  603,\n",
       "  1304,\n",
       "  1196,\n",
       "  229,\n",
       "  473,\n",
       "  50,\n",
       "  841,\n",
       "  766,\n",
       "  1632,\n",
       "  694,\n",
       "  1224,\n",
       "  693,\n",
       "  1125,\n",
       "  846,\n",
       "  49,\n",
       "  1649,\n",
       "  98,\n",
       "  182,\n",
       "  1623,\n",
       "  1620,\n",
       "  676,\n",
       "  994,\n",
       "  149,\n",
       "  629,\n",
       "  748,\n",
       "  897,\n",
       "  569,\n",
       "  1197,\n",
       "  1519,\n",
       "  79,\n",
       "  168,\n",
       "  1305,\n",
       "  54,\n",
       "  321,\n",
       "  1333,\n",
       "  532,\n",
       "  1309,\n",
       "  502,\n",
       "  1217,\n",
       "  720,\n",
       "  223,\n",
       "  144,\n",
       "  666,\n",
       "  59,\n",
       "  1236,\n",
       "  274,\n",
       "  825,\n",
       "  327,\n",
       "  1209,\n",
       "  594,\n",
       "  820,\n",
       "  1573,\n",
       "  91,\n",
       "  1460,\n",
       "  179,\n",
       "  847,\n",
       "  893,\n",
       "  1640,\n",
       "  729,\n",
       "  251,\n",
       "  886,\n",
       "  273,\n",
       "  1705,\n",
       "  1648,\n",
       "  747,\n",
       "  856,\n",
       "  68,\n",
       "  475,\n",
       "  1277,\n",
       "  289,\n",
       "  526,\n",
       "  1208,\n",
       "  1239,\n",
       "  1065,\n",
       "  1355,\n",
       "  53,\n",
       "  1536,\n",
       "  1677,\n",
       "  960,\n",
       "  1275,\n",
       "  621,\n",
       "  231,\n",
       "  451,\n",
       "  253,\n",
       "  129,\n",
       "  152,\n",
       "  936,\n",
       "  1463,\n",
       "  464,\n",
       "  705,\n",
       "  1098,\n",
       "  865,\n",
       "  309,\n",
       "  1030,\n",
       "  1007,\n",
       "  926,\n",
       "  1567,\n",
       "  1387,\n",
       "  567,\n",
       "  1162,\n",
       "  105,\n",
       "  407,\n",
       "  74,\n",
       "  88,\n",
       "  300,\n",
       "  1206,\n",
       "  653,\n",
       "  172,\n",
       "  25,\n",
       "  213,\n",
       "  888,\n",
       "  481,\n",
       "  1601,\n",
       "  468,\n",
       "  102,\n",
       "  134,\n",
       "  399,\n",
       "  517,\n",
       "  1247,\n",
       "  478,\n",
       "  734,\n",
       "  560,\n",
       "  1436,\n",
       "  1575,\n",
       "  97,\n",
       "  55,\n",
       "  43,\n",
       "  1433,\n",
       "  946,\n",
       "  18,\n",
       "  1158,\n",
       "  1203,\n",
       "  1458,\n",
       "  280,\n",
       "  1034,\n",
       "  922,\n",
       "  1222,\n",
       "  737,\n",
       "  1062,\n",
       "  508,\n",
       "  161,\n",
       "  1059,\n",
       "  1026,\n",
       "  432,\n",
       "  1114,\n",
       "  1328,\n",
       "  810,\n",
       "  1276,\n",
       "  101,\n",
       "  1109,\n",
       "  1671,\n",
       "  1164,\n",
       "  1563,\n",
       "  1408,\n",
       "  759,\n",
       "  549,\n",
       "  933,\n",
       "  963,\n",
       "  542,\n",
       "  1638,\n",
       "  677,\n",
       "  707,\n",
       "  763,\n",
       "  1134,\n",
       "  306,\n",
       "  1708,\n",
       "  561,\n",
       "  1215,\n",
       "  849,\n",
       "  80,\n",
       "  1428,\n",
       "  16,\n",
       "  177,\n",
       "  384,\n",
       "  1578,\n",
       "  615,\n",
       "  788,\n",
       "  1682,\n",
       "  424,\n",
       "  174,\n",
       "  1168,\n",
       "  814,\n",
       "  462,\n",
       "  465,\n",
       "  774,\n",
       "  1248,\n",
       "  1407,\n",
       "  23,\n",
       "  1405,\n",
       "  1055,\n",
       "  785,\n",
       "  1674,\n",
       "  521,\n",
       "  193,\n",
       "  1227,\n",
       "  654,\n",
       "  861,\n",
       "  1138,\n",
       "  333,\n",
       "  1005,\n",
       "  1608,\n",
       "  837,\n",
       "  1382,\n",
       "  337,\n",
       "  1503,\n",
       "  1404,\n",
       "  5,\n",
       "  84,\n",
       "  575,\n",
       "  600,\n",
       "  127,\n",
       "  1027,\n",
       "  1284,\n",
       "  721,\n",
       "  711,\n",
       "  106,\n",
       "  433,\n",
       "  178,\n",
       "  572,\n",
       "  649,\n",
       "  757,\n",
       "  595,\n",
       "  1509,\n",
       "  1374,\n",
       "  1072,\n",
       "  1336,\n",
       "  32,\n",
       "  447,\n",
       "  957,\n",
       "  1644,\n",
       "  1233,\n",
       "  874,\n",
       "  987,\n",
       "  974,\n",
       "  744,\n",
       "  107,\n",
       "  939,\n",
       "  1541,\n",
       "  553,\n",
       "  904,\n",
       "  550,\n",
       "  1111,\n",
       "  1547,\n",
       "  165,\n",
       "  379,\n",
       "  210,\n",
       "  999,\n",
       "  1702,\n",
       "  1662,\n",
       "  531,\n",
       "  429,\n",
       "  1676,\n",
       "  1327,\n",
       "  460,\n",
       "  12,\n",
       "  1432,\n",
       "  487,\n",
       "  568,\n",
       "  1122,\n",
       "  1651,\n",
       "  657,\n",
       "  1533,\n",
       "  702,\n",
       "  1281,\n",
       "  540,\n",
       "  1341,\n",
       "  164,\n",
       "  343,\n",
       "  1342,\n",
       "  211,\n",
       "  573,\n",
       "  784,\n",
       "  15,\n",
       "  1099,\n",
       "  493,\n",
       "  1544,\n",
       "  1141,\n",
       "  332,\n",
       "  786,\n",
       "  291,\n",
       "  212,\n",
       "  471,\n",
       "  514,\n",
       "  682,\n",
       "  1316,\n",
       "  439,\n",
       "  1506,\n",
       "  46,\n",
       "  1424,\n",
       "  898,\n",
       "  840,\n",
       "  527,\n",
       "  753,\n",
       "  136,\n",
       "  150,\n",
       "  1092,\n",
       "  992,\n",
       "  1050,\n",
       "  787,\n",
       "  877,\n",
       "  396,\n",
       "  771,\n",
       "  1166,\n",
       "  873,\n",
       "  372,\n",
       "  469,\n",
       "  448,\n",
       "  436,\n",
       "  250,\n",
       "  119,\n",
       "  196,\n",
       "  1521,\n",
       "  1401,\n",
       "  417,\n",
       "  346,\n",
       "  354,\n",
       "  633,\n",
       "  1207,\n",
       "  574,\n",
       "  1668,\n",
       "  434,\n",
       "  663,\n",
       "  334,\n",
       "  345,\n",
       "  103,\n",
       "  82,\n",
       "  1028,\n",
       "  1308,\n",
       "  10,\n",
       "  546,\n",
       "  687,\n",
       "  244,\n",
       "  1014,\n",
       "  559,\n",
       "  996,\n",
       "  135,\n",
       "  1389,\n",
       "  482,\n",
       "  1621,\n",
       "  303,\n",
       "  979,\n",
       "  1110,\n",
       "  236,\n",
       "  440,\n",
       "  41,\n",
       "  528,\n",
       "  45,\n",
       "  1108,\n",
       "  1625,\n",
       "  1020,\n",
       "  761,\n",
       "  991,\n",
       "  625,\n",
       "  197,\n",
       "  116,\n",
       "  855,\n",
       "  924,\n",
       "  490,\n",
       "  455,\n",
       "  1038,\n",
       "  1489,\n",
       "  459,\n",
       "  1299,\n",
       "  3,\n",
       "  336,\n",
       "  640,\n",
       "  1163,\n",
       "  1219,\n",
       "  1530,\n",
       "  1100,\n",
       "  1455,\n",
       "  510,\n",
       "  246,\n",
       "  383,\n",
       "  969,\n",
       "  1360,\n",
       "  1500,\n",
       "  120,\n",
       "  442,\n",
       "  1398,\n",
       "  1182,\n",
       "  1707,\n",
       "  30,\n",
       "  1257,\n",
       "  279,\n",
       "  1679,\n",
       "  1396,\n",
       "  1077,\n",
       "  1318,\n",
       "  723,\n",
       "  815],\n",
       " 3: [1607,\n",
       "  1502,\n",
       "  1295,\n",
       "  1580,\n",
       "  1481,\n",
       "  1637,\n",
       "  1421,\n",
       "  1265,\n",
       "  1724,\n",
       "  1565,\n",
       "  1673,\n",
       "  1133,\n",
       "  1718,\n",
       "  1151,\n",
       "  1238,\n",
       "  1589,\n",
       "  1583,\n",
       "  1646,\n",
       "  1715,\n",
       "  1556,\n",
       "  1106,\n",
       "  1664,\n",
       "  1454,\n",
       "  1130,\n",
       "  1268,\n",
       "  1430,\n",
       "  1511,\n",
       "  1097,\n",
       "  1457,\n",
       "  1508,\n",
       "  1529,\n",
       "  1256,\n",
       "  1286,\n",
       "  1175,\n",
       "  1619,\n",
       "  1475,\n",
       "  1448,\n",
       "  1160,\n",
       "  1241,\n",
       "  1691,\n",
       "  1616,\n",
       "  1610,\n",
       "  1592,\n",
       "  1283,\n",
       "  1472,\n",
       "  1232,\n",
       "  1697,\n",
       "  1259,\n",
       "  1688,\n",
       "  1178]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "512ec24e",
   "metadata": {},
   "source": [
    "We initialize the model and the sets K, N_L, N_B, I, I_k, N_L_L, N_L_R and f_s are declared abstractly using the Set component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6513133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Initializing ordered Set I with a fundamentally unordered data source\n",
      "    (type: set).  This WILL potentially lead to nondeterministic behavior in\n",
      "    Pyomo\n",
      "WARNING: Initializing ordered Set N_B with a fundamentally unordered data\n",
      "    source (type: set).  This WILL potentially lead to nondeterministic\n",
      "    behavior in Pyomo\n"
     ]
    }
   ],
   "source": [
    "model = ConcreteModel() #ConcretModel()\n",
    "# Instances & Classes\n",
    "# Assume a dict I_in_k, with keys k and values of a list of I's in that k\n",
    "\n",
    "model.I = Set(initialize=set(i for k in I_in_k for i in I_in_k[k]))\n",
    "model.K = Set(initialize=I_in_k.keys())\n",
    "model.I_k = Set(model.K,initialize=I_in_k)  # <----- questa linea la ho cambiata se no non mi funzionava\n",
    "\n",
    "# Features\n",
    "model.f_s =Set(initialize=index_features)\n",
    "\n",
    "# Nodes Leaf N_L & Nodes Breanch N_B\n",
    "model.N_B = Set(initialize=set(i for k in BF_in_NL_R for i in BF_in_NL_R[k]))\n",
    "model.N_L = Set(initialize=BF_in_NL_R.keys())\n",
    "model.N_L_R = Set(model.N_L,initialize=B_in_NR)\n",
    "model.N_L_L = Set(model.N_L,initialize=B_in_NL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ed5b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Rule failed for Param 'x' with index (1710, 0): ValueError: Invalid\n",
      "    parameter value: x[(1710, 0)] = '-1.3416407864998738', value type=<class\n",
      "    'numpy.float64'>.\n",
      "    \tValue not in parameter domain NonNegativeReals\n",
      "ERROR: Constructing component 'x' from data=None failed: ValueError: Invalid\n",
      "    parameter value: x[(1710, 0)] = '-1.3416407864998738', value type=<class\n",
      "    'numpy.float64'>.\n",
      "    \tValue not in parameter domain NonNegativeReals\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter value: x[(1710, 0)] = '-1.3416407864998738', value type=<class 'numpy.float64'>.\n\tValue not in parameter domain NonNegativeReals",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12210/3598288933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Value for the instance i-th of the feature j-th\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNonNegativeReals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <--- ho dovuto pure modificare questa linea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/block.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, val)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0;31m# Pyomo components are added with the add_component method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/block.py\u001b[0m in \u001b[0;36madd_component\u001b[0;34m(self, name, val)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                              _blockName, str(data))\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/param.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;31m# Step #1: initialize data from rule value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_from_rule_using_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;31m# Step #2: allow any user-specified (external) data to override\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py\u001b[0m in \u001b[0;36m_construct_from_rule_using_setitem\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;31m# The index is coming in externally; we need to validate it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                 \u001b[0;31m# If the index is not finite, then we cannot iterate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/indexed_component.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, index, val)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NotFound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_NotFound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_when_not_present\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/param.py\u001b[0m in \u001b[0;36m_setitem_when_not_present\u001b[0;34m(self, index, value, _check_domain)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;31m# Because we do not have a _ParamData, we cannot rely on the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0;31m# validation that occurs in _ParamData.set_value()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_domain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/param.py\u001b[0m in \u001b[0;36m_validate_value\u001b[0;34m(self, index, value, validate_domain, data)\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNOTSET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    676\u001b[0m                 \u001b[0;34m\"Invalid parameter value: %s[%s] = '%s', value type=%s.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;34m\"\\tValue not in parameter domain %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter value: x[(1710, 0)] = '-1.3416407864998738', value type=<class 'numpy.float64'>.\n\tValue not in parameter domain NonNegativeReals"
     ]
    }
   ],
   "source": [
    "# Cost of misclassification\n",
    "model.W = Param(model.K, model.K, within=NonNegativeReals, initialize=my_W)\n",
    "\n",
    "# Value for the instance i-th of the feature j-th\n",
    "model.x = Param(model.I, model.f_s, within=NonNegativeReals, initialize=my_x) # <--- ho dovuto pure modificare questa linea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6f796",
   "metadata": {},
   "source": [
    "The __Var__ component is used to define the decision variables. No longer a random init is done, but the fitted parameters are assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec94652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random initialization\n",
    "\n",
    "init_a = np.random.uniform(low=-1.0, high=1.0, size=None)\n",
    "init_mu = np.random.uniform(low=-1.0, high=1.0, size=None)\n",
    "init_C = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "init_P = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "init_p = np.random.uniform(low=0.0, high=1.0, size=None)\n",
    "\n",
    "\n",
    "# The weigths of feature j-th in breanch node t-th\n",
    "model.a = Var(model.f_s, model.N_B, within=Reals, bounds = (-1.0,1.0),initialize=init_a)\n",
    "\n",
    "# The intercepts of the linear combinations correspond to decision variables\n",
    "model.mu = Var(model.N_B, within = Reals, bounds = (-1.0,1.0),initialize=init_mu)\n",
    "\n",
    "# The variables thtat take into account if node t is labeled with class k\n",
    "model.C = Var(model.K, model.N_L, within = PercentFraction,initialize=init_C)\n",
    "\n",
    "# An auxiliary variables\n",
    "model.P = Var(model.I,model.N_L,within = PercentFraction,initialize=init_P)\n",
    "model.p = Var(model.I,model.N_B,within = PercentFraction,initialize=init_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c026b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees",
   "language": "python",
   "name": "decision_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
