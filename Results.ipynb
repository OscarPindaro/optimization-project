{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6609937",
   "metadata": {},
   "source": [
    "# Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a9046c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe management\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyomo.environ import *\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sorct import SORCT\n",
    "from src.cluster import HierarchicalLogisticRegression, best_leaf_assignment\n",
    "from src.utils import get_number_of_iterations\n",
    "from sklearn.model_selection import KFold\n",
    "from src.cluster import find_best_estimator\n",
    "from pyomo.opt import SolverStatus, TerminationCondition\n",
    "import pickle\n",
    "import run_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2646e997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_0</th>\n",
       "      <th>Iterations_0</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_Train_0</th>\n",
       "      <th>Time_1</th>\n",
       "      <th>Iterations_1</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_Train_1</th>\n",
       "      <th>Time_2</th>\n",
       "      <th>Iterations_2</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Score_Train_2</th>\n",
       "      <th>Time_3</th>\n",
       "      <th>Iterations_3</th>\n",
       "      <th>Score_3</th>\n",
       "      <th>Score_Train_3</th>\n",
       "      <th>Time_4</th>\n",
       "      <th>Iterations_4</th>\n",
       "      <th>Score_4</th>\n",
       "      <th>Score_Train_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SORCT</th>\n",
       "      <td>1.226723</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.218063</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.329288</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>9.636462</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time_0  Iterations_0  Score_0  Score_Train_0    Time_1  Iterations_1  \\\n",
       "SORCT  1.226723          98.0      0.6       0.741667  0.218063           6.0   \n",
       "\n",
       "        Score_1  Score_Train_1  Time_2  Iterations_2  Score_2  Score_Train_2  \\\n",
       "SORCT  0.333333       0.333333    -1.0          -1.0     -1.0           -1.0   \n",
       "\n",
       "         Time_3  Iterations_3   Score_3  Score_Train_3    Time_4  \\\n",
       "SORCT  2.329288         154.0  0.633333       0.733333  9.636462   \n",
       "\n",
       "       Iterations_4   Score_4  Score_Train_4  \n",
       "SORCT         298.0  0.766667            0.7  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_path = \"results\"\n",
    "#names = [\"car\", \"iris\", \"seeds_data\", \"new_thyroid\", \"splice\"]\n",
    "names = [\"iris\"]\n",
    "path = os.path.join(res_path, \"{}_results.csv\".format(names[0]))\n",
    "df = pd.read_csv(path, sep=\" \", index_col=0)\n",
    "rob = pd.read_csv(\"results/iris_sorct.csv\", sep=\" \", index_col=0)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dcc59b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HLR_Score_Train_0</th>\n",
       "      <th>SORCT_Score_Train_0</th>\n",
       "      <th>HLR_Score_Train_1</th>\n",
       "      <th>SORCT_Score_Train_1</th>\n",
       "      <th>HLR_Score_Train_2</th>\n",
       "      <th>SORCT_Score_Train_2</th>\n",
       "      <th>HLR_Score_Train_3</th>\n",
       "      <th>SORCT_Score_Train_3</th>\n",
       "      <th>HLR_Score_Train_4</th>\n",
       "      <th>SORCT_Score_Train_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kmeans</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agglomerative_sigle</th>\n",
       "      <td>0.691667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_labels</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HLR_Score_Train_0  SORCT_Score_Train_0  \\\n",
       "kmeans                        0.000000             0.741667   \n",
       "Agglomerative_sigle           0.691667            -1.000000   \n",
       "birch                         0.000000             0.741667   \n",
       "True_labels                   0.600000            -1.000000   \n",
       "\n",
       "                     HLR_Score_Train_1  SORCT_Score_Train_1  \\\n",
       "kmeans                        0.041667             0.708333   \n",
       "Agglomerative_sigle           0.625000             0.708333   \n",
       "birch                         0.333333             0.333333   \n",
       "True_labels                   0.666667             0.708333   \n",
       "\n",
       "                     HLR_Score_Train_2  SORCT_Score_Train_2  \\\n",
       "kmeans                        0.041667             0.683333   \n",
       "Agglomerative_sigle           0.641667             0.683333   \n",
       "birch                         0.041667             0.683333   \n",
       "True_labels                   0.641667             0.683333   \n",
       "\n",
       "                     HLR_Score_Train_3  SORCT_Score_Train_3  \\\n",
       "kmeans                        0.041667             0.733333   \n",
       "Agglomerative_sigle           0.691667             0.733333   \n",
       "birch                         0.000000             0.733333   \n",
       "True_labels                   0.608333             0.733333   \n",
       "\n",
       "                     HLR_Score_Train_4  SORCT_Score_Train_4  \n",
       "kmeans                        0.000000                 -1.0  \n",
       "Agglomerative_sigle           0.641667                  0.7  \n",
       "birch                         0.058333                 -1.0  \n",
       "True_labels                   0.641667                  0.7  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[col for col in df.columns if \"Train\" in col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9a386162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "IGNORE_HLR_TIME = True\n",
    "N_FOLDS = 5\n",
    "dfs = []\n",
    "for file_index in range(len(names)):\n",
    "    name = names[file_index]\n",
    "    path = os.path.join(res_path, \"{}_results.csv\".format(name))\n",
    "    df = pd.read_csv(path, sep=\" \", index_col=0)\n",
    "    sorct_df = pd.read_csv(os.path.join(res_path,\"{}_sorct.csv\".format(name)), sep=\" \", index_col=0)\n",
    "    if -1 in df or -2 in df or -3 in df:\n",
    "        print(\"Some folds were not computed\")\n",
    "    res_index = df.index\n",
    "    res_index = res_index.append(sorct_df.index)\n",
    "    result_df = pd.DataFrame(index=res_index)\n",
    "    \n",
    "    \n",
    "    for cl_name in res_index:\n",
    "        \n",
    "        \n",
    "        n_invalid = 0\n",
    "        n_invalid_sorct = 0\n",
    "        time = 0\n",
    "        hlr_time = 0\n",
    "        iters = 0\n",
    "        hlr_score = 0\n",
    "        sorct_score = 0\n",
    "        hs = 0\n",
    "        cp = 0\n",
    "        sorct_train_score = 0\n",
    "        hlr_train_score = 0\n",
    "        # sorct no init values\n",
    "        no_init_time = 0\n",
    "        no_init_iters = 0\n",
    "        no_init_score = 0\n",
    "        no_init_train_score = 0\n",
    "        for fold_index in range(N_FOLDS):\n",
    "            if cl_name != \"SORCT\":\n",
    "                if df.loc[cl_name,\"Time_{}\".format(fold_index)] < 0:\n",
    "                    print( df.loc[cl_name,\"Time_{}\".format(fold_index)])\n",
    "                    n_invalid += 1\n",
    "                else:\n",
    "                    time += df.loc[cl_name,\"Time_{}\".format(fold_index)]\n",
    "                    if not IGNORE_HLR_TIME:\n",
    "                        hlr_time += df.loc[cl_name, \"HLR_Time_{}\".format(fold_index)]\n",
    "                    iters += df.loc[cl_name, \"Iterations_{}\".format(fold_index)]\n",
    "                    hlr_score += df.loc[cl_name, \"HLR_Score_{}\".format(fold_index)]\n",
    "                    sorct_score += df.loc[cl_name, \"SORCT_Score_{}\".format(fold_index)]\n",
    "                    hs += df.loc[cl_name, \"Homogeneity_{}\".format(fold_index)]\n",
    "                    cp += df.loc[cl_name, \"Completeness_{}\".format(fold_index)]\n",
    "                    sorct_train_score += df.loc[cl_name, \"SORCT_Score_Train_{}\".format(fold_index)]\n",
    "                    hlr_train_score += df.loc[cl_name, \"HLR_Score_Train_{}\".format(fold_index)]\n",
    "            # else sorct no init\n",
    "            else:\n",
    "                if  sorct_df.loc[\"SORCT\", \"Time_{}\".format(fold_index) ] < 0:\n",
    "                    n_invalid_sorct +=1\n",
    "                    print(sorct_df.loc[\"SORCT\", \"Time_{}\".format(fold_index) ])\n",
    "                else:\n",
    "                    no_init_time += sorct_df.loc[\"SORCT\", \"Time_{}\".format(fold_index) ]\n",
    "                    no_init_iters +=  sorct_df.loc[\"SORCT\", \"Iterations_{}\".format(fold_index) ]\n",
    "                    no_init_score +=  sorct_df.loc[\"SORCT\", \"Score_{}\".format(fold_index) ]\n",
    "                    no_init_train_score += sorct_df.loc[\"SORCT\", \"Score_Train_{}\".format(fold_index) ]\n",
    "        if cl_name != \"SORCT\":\n",
    "            real_folds = N_FOLDS - n_invalid\n",
    "            time = time / real_folds\n",
    "            hlr_time = hlr_time / real_folds\n",
    "            iters = iters / real_folds\n",
    "            hlr_score = hlr_score / real_folds\n",
    "            sorct_score = sorct_score / real_folds\n",
    "            hs = hs / real_folds\n",
    "            cp = cp / real_folds\n",
    "            sorct_train_score = sorct_train_score / real_folds\n",
    "            hlr_train_score = hlr_train_score / real_folds\n",
    "            result_df.loc[cl_name, \"Time\"] = time\n",
    "            if not IGNORE_HLR_TIME:\n",
    "                result_df.loc[cl_name, \"HLR_Time\"] = hlr_time\n",
    "            result_df.loc[cl_name, \"Iterations\"] = iters\n",
    "            result_df.loc[cl_name, \"Train_HLR_Score\"] = hlr_train_score\n",
    "            result_df.loc[cl_name, \"Train_SORCT_Score\"] = sorct_train_score\n",
    "            result_df.loc[cl_name, \"HLR_Score\"] = hlr_score\n",
    "            result_df.loc[cl_name, \"SORCT_Score\"] = sorct_score\n",
    "            result_df.loc[cl_name, \"Homogeneity\"] = hs\n",
    "            result_df.loc[cl_name, \"Completeness\"] = cp\n",
    "            result_df.loc[cl_name, \"Invalid Folds\"] = n_invalid \n",
    "        else:\n",
    "            n_folds_reals = N_FOLDS - n_invalid_sorct\n",
    "            result_df.loc[cl_name, \"Invalid Folds\"] = n_invalid_sorct \n",
    "            result_df.loc[cl_name, \"Time\"] = no_init_time / n_folds_reals\n",
    "            result_df.loc[cl_name, \"Iterations\"] = no_init_iters / n_folds_reals\n",
    "            result_df.loc[cl_name, \"SORCT_Score\"] = no_init_score / n_folds_reals\n",
    "            result_df.loc[cl_name, \"Train_SORCT_Score\"] = no_init_train_score / n_folds_reals\n",
    "\n",
    "    #result_df[\"Invalid Folds\"] = result_df[\"Invalid Folds\"].astype(\"int32\")\n",
    "    dfs.append(result_df)\n",
    "    result_df.to_csv(os.path.join(res_path, \"{}_final.csv\".format(name)), float_format='%.2f')\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2df9d0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Train_HLR_Score</th>\n",
       "      <th>Train_SORCT_Score</th>\n",
       "      <th>HLR_Score</th>\n",
       "      <th>SORCT_Score</th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Invalid Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kmeans</th>\n",
       "      <td>2.401418</td>\n",
       "      <td>153.75</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.605956</td>\n",
       "      <td>0.761197</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agglomerative_sigle</th>\n",
       "      <td>2.417294</td>\n",
       "      <td>159.50</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.608248</td>\n",
       "      <td>0.788216</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birch</th>\n",
       "      <td>2.952133</td>\n",
       "      <td>183.00</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.622917</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_labels</th>\n",
       "      <td>3.780773</td>\n",
       "      <td>222.50</td>\n",
       "      <td>0.639583</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SORCT</th>\n",
       "      <td>3.352634</td>\n",
       "      <td>139.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.627083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Time  Iterations  Train_HLR_Score  Train_SORCT_Score  \\\n",
       "kmeans               2.401418      153.75         0.031250           0.716667   \n",
       "Agglomerative_sigle  2.417294      159.50         0.650000           0.706250   \n",
       "birch                2.952133      183.00         0.093750           0.622917   \n",
       "True_labels          3.780773      222.50         0.639583           0.706250   \n",
       "SORCT                3.352634      139.00              NaN           0.627083   \n",
       "\n",
       "                     HLR_Score  SORCT_Score  Homogeneity  Completeness  \\\n",
       "kmeans                0.050000     0.641667     0.605956      0.761197   \n",
       "Agglomerative_sigle   0.616667     0.683333     0.608248      0.788216   \n",
       "birch                 0.100000     0.541667     0.000000      1.000000   \n",
       "True_labels           0.716667     0.683333     1.000000      1.000000   \n",
       "SORCT                      NaN     0.583333          NaN           NaN   \n",
       "\n",
       "                     Invalid Folds  \n",
       "kmeans                         1.0  \n",
       "Agglomerative_sigle            1.0  \n",
       "birch                          1.0  \n",
       "True_labels                    1.0  \n",
       "SORCT                          1.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a259b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37794/2369220504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SORCT_Score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SORCT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    index = list(df.index)\n",
    "    fig, ax = plt.subplots()\n",
    "    values = df[\"SORCT_Score\"]\n",
    "    values = values/values.loc[\"SORCT\"]\n",
    "    ax.bar(index, values)\n",
    "    ax.set_ylim([0.8,1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    index = list(df.index)\n",
    "    fig, ax = plt.subplots()\n",
    "    values = df[\"Time\"]\n",
    "    values = values/values.loc[\"SORCT\"]\n",
    "    ax.bar(index, values)\n",
    "    ax.set_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35aadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    index = list(df.index)\n",
    "    fig, ax = plt.subplots()\n",
    "    values = df[\"Iterations\"]\n",
    "    values = values/values.loc[\"SORCT\"]\n",
    "    ax.bar(index, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be9eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac36cb",
   "metadata": {},
   "source": [
    "## Test train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_list = [\"car\", \"iris\",\"new_thyroid\", \"seeds_data\", \"splice\"]\n",
    "N_SPLITS = 5\n",
    "OPT_TYPE = \"simple\"\n",
    "SEED = 1234\n",
    "for dataset_name in dataset_name_list:\n",
    "    if dataset_name == \"iris\":\n",
    "        X, y = datasets.load_iris(as_frame=True, return_X_y=True)\n",
    "        df = pd.DataFrame(X)\n",
    "        df[\"Classes\"] = y\n",
    "    elif dataset_name == \"car\":\n",
    "        dataset_path = os.path.join(\"datasets\", \"{}.csv\".format(dataset_name))\n",
    "        df = pd.read_csv(dataset_path, delimiter=\";\", header=0)\n",
    "        df = df.convert_dtypes()\n",
    "        # dictionary converting ordinal categories to values\n",
    "        cost_dict = {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3}\n",
    "        doors_dict = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
    "        persons_dict = {\"2\": 2, \"4\": 4, \"more\": 5}\n",
    "        dimension_dict = {\"small\": 0, \"med\": 1, \"big\": 2}\n",
    "        # buying\n",
    "        df[\"buying\"] = df[\"buying\"].apply(lambda x: cost_dict[x])\n",
    "        df[\"maint\"] = df[\"maint\"].apply(lambda x: cost_dict[x])\n",
    "        df[\"doors\"] = df[\"doors\"].apply(lambda x: doors_dict[x])\n",
    "        df[\"persons\"] = df[\"persons\"].apply(lambda x: persons_dict[x])\n",
    "        df[\"lug_boot\"] = df[\"lug_boot\"].apply(lambda x: dimension_dict[x])\n",
    "        df[\"safety\"] = df[\"safety\"].apply(lambda x: cost_dict[x])\n",
    "        classes_encoder = preprocessing.LabelEncoder().fit(df[\"Classes\"])\n",
    "        df[\"Classes\"] = classes_encoder.transform(df[\"Classes\"])\n",
    "    else:\n",
    "        dataset_path = os.path.join(\"datasets\", \"{}.csv\".format(dataset_name))\n",
    "        df = pd.read_csv(dataset_path, delimiter=\";\", header=0)\n",
    "    if \"Id\" in df:\n",
    "        df = df.drop('Id', axis=1)\n",
    "    df_std = df.copy()\n",
    "    scaler = MinMaxScaler()  # also MaxAbsScaler()\n",
    "    # Preprocessing: we get the columns names of features which have to be standardized\n",
    "    columns_names = list(df)\n",
    "    index_features = list(range(0, len(df_std.columns) - 1))\n",
    "    # The name of the classes K\n",
    "    classes = df_std['Classes'].unique().tolist()\n",
    "    classes_en = [i for i in range(len(classes))]\n",
    "    # Encoder processing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_std['Classes'])\n",
    "    df_std['Classes'] = le.transform(df_std['Classes'])\n",
    "    # Scaling phase\n",
    "    df_std[columns_names[0:-1]] = scaler.fit_transform(df_std[columns_names[0:-1]])\n",
    "    for column in columns_names[0:-1]:\n",
    "        # TODO janky solution to unreliable MinMaxScaler behaviour\n",
    "        df_std.loc[df[column] > 1, column] = 1\n",
    "        df_std.loc[df[column] < 0, column] = 0\n",
    "\n",
    "    X = df_std[columns_names[:-1]]\n",
    "    y = df_std[columns_names[-1]]\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    n_leaves = 4\n",
    "    fold_index = 0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        print(\"Fold\", fold_index)\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        df_train = pd.concat([X_train, y_train], axis=1)\n",
    "        df_test = pd.concat([X_test, y_test], axis=1)\n",
    "        # sample weightingsorct_iters\n",
    "        occurences = [len(y_train[y_train == x]) for x in classes]\n",
    "        total_samples = sum(occurences)\n",
    "        sample_weight = np.zeros_like(y_train)\n",
    "        for class_index, n_occurr in zip(classes, occurences):\n",
    "            sample_weight[y_train == class_index] = n_occurr\n",
    "        sample_weight = sample_weight / total_samples\n",
    "        #HLR_car_Agglomerative_sigle_0.pkl\n",
    "        # HLR\n",
    "        # true labels\n",
    "        filename = \"HLR_{}_{}_{}.pkl\".format(\"tl\",dataset_name, fold_index)\n",
    "        with open(os.path.join(\"results\", filename), \"rb\") as f:\n",
    "            hlr = pickle.load(f)\n",
    "        run_tests.create_model()\n",
    "        \n",
    "        fold_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf42baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/SORCT_new_thyroid_birch_4.pkl\", \"rb\") as f:\n",
    "    roba = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "roba.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08590ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "roba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641189ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e26bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = pd.DataFrame(index=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.loc[\"a\",\"culo\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.loc[\"d\", \"culo\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.index.append([\"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17605ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cc0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\"datasets\", \"car.csv\")\n",
    "df = pd.read_csv(dataset_path, delimiter=\";\", header=0)\n",
    "df = df.convert_dtypes()\n",
    "# dictionary converting ordinal categories to values\n",
    "cost_dict = {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3}\n",
    "doors_dict = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
    "persons_dict = {\"2\": 2, \"4\": 4, \"more\": 5}\n",
    "dimension_dict = {\"small\": 0, \"med\": 1, \"big\": 2}\n",
    "# buying\n",
    "df[\"buying\"] = df[\"buying\"].apply(lambda x: cost_dict[x])\n",
    "df[\"maint\"] = df[\"maint\"].apply(lambda x: cost_dict[x])\n",
    "df[\"doors\"] = df[\"doors\"].apply(lambda x: doors_dict[x])\n",
    "df[\"persons\"] = df[\"persons\"].apply(lambda x: persons_dict[x])\n",
    "df[\"lug_boot\"] = df[\"lug_boot\"].apply(lambda x: dimension_dict[x])\n",
    "df[\"safety\"] = df[\"safety\"].apply(lambda x: cost_dict[x])\n",
    "classes_encoder = preprocessing.LabelEncoder().fit(df[\"Classes\"])\n",
    "df[\"Classes\"] = classes_encoder.transform(df[\"Classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d249b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,    2,    3,    5,    6,    7,    8,    9,   10,   12,\n",
       "            ...\n",
       "            1715, 1716, 1717, 1718, 1719, 1720, 1722, 1724, 1725, 1726],\n",
       "           dtype='int64', length=1296)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_SPLITS = 4\n",
    "SEED = 1234\n",
    "n_feature = len(df.columns)-1\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "X = df[df.columns[0:n_feature]]\n",
    "y = df[\"Classes\"]\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    df_test = pd.concat([X_test, y_test], axis=1)\n",
    "    train_index = df_train.index\n",
    "    break\n",
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381ba696",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"HLR_tl_car_0.pkl\"\n",
    "with open(os.path.join(\"results\", filename), \"rb\") as f:\n",
    "    hlr_dict = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f206f7c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37794/2405037766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOPT_TYPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"simple\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhlr_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPT_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhlr_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_projects/optimization-project/train_test.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(init, opt_tipe, df_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_tipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mI_in_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Classes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSORCT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_in_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI_in_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI_in_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classes_en' is not defined"
     ]
    }
   ],
   "source": [
    "OPT_TYPE = \"simple\"\n",
    "init  = train_test.get_model_init(hlr_dict, range(0,6), train_index, [0,1,2])\n",
    "model = train_test.create_model(init, OPT_TYPE, df_train)\n",
    "hlr_score = train_test.predict(model, X_train, y_train, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095ab00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees",
   "language": "python",
   "name": "decision_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
