{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6609937",
   "metadata": {},
   "source": [
    "# Results visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a9046c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe management\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyomo.environ import *\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sorct import SORCT\n",
    "from src.cluster import HierarchicalLogisticRegression, best_leaf_assignment\n",
    "from src.utils import get_number_of_iterations\n",
    "from sklearn.model_selection import KFold\n",
    "from src.cluster import find_best_estimator\n",
    "from pyomo.opt import SolverStatus, TerminationCondition\n",
    "import pickle\n",
    "import run_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2646e997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_0</th>\n",
       "      <th>Iterations_0</th>\n",
       "      <th>Score_0</th>\n",
       "      <th>Score_Train_0</th>\n",
       "      <th>Time_1</th>\n",
       "      <th>Iterations_1</th>\n",
       "      <th>Score_1</th>\n",
       "      <th>Score_Train_1</th>\n",
       "      <th>Time_2</th>\n",
       "      <th>Iterations_2</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>Score_Train_2</th>\n",
       "      <th>Time_3</th>\n",
       "      <th>Iterations_3</th>\n",
       "      <th>Score_3</th>\n",
       "      <th>Score_Train_3</th>\n",
       "      <th>Time_4</th>\n",
       "      <th>Iterations_4</th>\n",
       "      <th>Score_4</th>\n",
       "      <th>Score_Train_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SORCT</th>\n",
       "      <td>0.186198</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3.768789</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>5.793448</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>2.271399</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>3.261475</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time_0  Iterations_0   Score_0  Score_Train_0    Time_1  \\\n",
       "SORCT  0.186198           7.0  0.266667           0.35  3.768789   \n",
       "\n",
       "       Iterations_1   Score_1  Score_Train_1    Time_2  Iterations_2  Score_2  \\\n",
       "SORCT         233.0  0.733333       0.708333  5.793448         253.0      0.6   \n",
       "\n",
       "       Score_Train_2    Time_3  Iterations_3   Score_3  Score_Train_3  \\\n",
       "SORCT       0.683333  2.271399         129.0  0.633333       0.733333   \n",
       "\n",
       "         Time_4  Iterations_4   Score_4  Score_Train_4  \n",
       "SORCT  3.261475         129.0  0.766667            0.7  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_path = \"results\"\n",
    "#names = [\"car\", \"iris\", \"seeds_data\", \"new_thyroid\", \"splice\"]\n",
    "names = [\"iris\", \"car\"]\n",
    "path = os.path.join(res_path, \"{}_results.csv\".format(names[0]))\n",
    "df = pd.read_csv(path, sep=\" \", index_col=0)\n",
    "rob = pd.read_csv(\"results/iris_sorct.csv\", sep=\" \", index_col=0)\n",
    "rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e2dded85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_0</th>\n",
       "      <th>HLR_Time_0</th>\n",
       "      <th>Iterations_0</th>\n",
       "      <th>HLR_Score_0</th>\n",
       "      <th>SORCT_Score_0</th>\n",
       "      <th>Homogeneity_0</th>\n",
       "      <th>Completeness_0</th>\n",
       "      <th>Time_1</th>\n",
       "      <th>HLR_Time_1</th>\n",
       "      <th>Iterations_1</th>\n",
       "      <th>...</th>\n",
       "      <th>HLR_Score_Train_0</th>\n",
       "      <th>SORCT_Score_Train_0</th>\n",
       "      <th>HLR_Score_Train_1</th>\n",
       "      <th>SORCT_Score_Train_1</th>\n",
       "      <th>HLR_Score_Train_2</th>\n",
       "      <th>SORCT_Score_Train_2</th>\n",
       "      <th>HLR_Score_Train_3</th>\n",
       "      <th>SORCT_Score_Train_3</th>\n",
       "      <th>HLR_Score_Train_4</th>\n",
       "      <th>SORCT_Score_Train_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kmeans</th>\n",
       "      <td>6.788942</td>\n",
       "      <td>0.020671</td>\n",
       "      <td>278</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.621987</td>\n",
       "      <td>0.795115</td>\n",
       "      <td>3.710655</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agglomerative_sigle</th>\n",
       "      <td>8.302376</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>385</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.621987</td>\n",
       "      <td>0.795115</td>\n",
       "      <td>0.209205</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birch</th>\n",
       "      <td>0.194040</td>\n",
       "      <td>0.026767</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.389553</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.358333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_labels</th>\n",
       "      <td>3.387764</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>131</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.715280</td>\n",
       "      <td>0.016640</td>\n",
       "      <td>301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Time_0  HLR_Time_0  Iterations_0  HLR_Score_0  \\\n",
       "kmeans               6.788942    0.020671           278          0.7   \n",
       "Agglomerative_sigle  8.302376    0.017759           385          0.7   \n",
       "birch                0.194040    0.026767             8          0.7   \n",
       "True_labels          3.387764    0.018522           131          0.7   \n",
       "\n",
       "                     SORCT_Score_0  Homogeneity_0  Completeness_0    Time_1  \\\n",
       "kmeans                    0.600000       0.621987        0.795115  3.710655   \n",
       "Agglomerative_sigle       0.600000       0.621987        0.795115  0.209205   \n",
       "birch                     0.266667       0.000000        1.000000  7.389553   \n",
       "True_labels               0.600000       1.000000        1.000000  6.715280   \n",
       "\n",
       "                     HLR_Time_1  Iterations_1  ...  HLR_Score_Train_0  \\\n",
       "kmeans                 0.018154           143  ...                0.6   \n",
       "Agglomerative_sigle    0.016340             6  ...                0.6   \n",
       "birch                  0.013460           289  ...                0.6   \n",
       "True_labels            0.016640           301  ...                0.6   \n",
       "\n",
       "                     SORCT_Score_Train_0  HLR_Score_Train_1  \\\n",
       "kmeans                          0.741667           0.666667   \n",
       "Agglomerative_sigle             0.741667           0.666667   \n",
       "birch                           0.350000           0.666667   \n",
       "True_labels                     0.741667           0.666667   \n",
       "\n",
       "                     SORCT_Score_Train_1  HLR_Score_Train_2  \\\n",
       "kmeans                          0.708333           0.641667   \n",
       "Agglomerative_sigle             0.333333           0.641667   \n",
       "birch                           0.708333           0.641667   \n",
       "True_labels                     0.708333           0.641667   \n",
       "\n",
       "                     SORCT_Score_Train_2  HLR_Score_Train_3  \\\n",
       "kmeans                          0.683333           0.608333   \n",
       "Agglomerative_sigle             0.683333           0.608333   \n",
       "birch                           0.683333           0.608333   \n",
       "True_labels                     0.683333           0.608333   \n",
       "\n",
       "                     SORCT_Score_Train_3  HLR_Score_Train_4  \\\n",
       "kmeans                          0.733333              0.625   \n",
       "Agglomerative_sigle             0.733333              0.625   \n",
       "birch                           0.733333              0.625   \n",
       "True_labels                     0.733333              0.625   \n",
       "\n",
       "                     SORCT_Score_Train_4  \n",
       "kmeans                          0.700000  \n",
       "Agglomerative_sigle             0.700000  \n",
       "birch                           0.358333  \n",
       "True_labels                     0.700000  \n",
       "\n",
       "[4 rows x 45 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a386162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "IGNORE_HLR_TIME = True\n",
    "N_FOLDS = 5\n",
    "dfs = []\n",
    "for file_index in range(len(names)):\n",
    "    name = names[file_index]\n",
    "    path = os.path.join(res_path, \"{}_results.csv\".format(name))\n",
    "    df = pd.read_csv(path, sep=\" \", index_col=0)\n",
    "    sorct_df = pd.read_csv(os.path.join(res_path,\"{}_sorct.csv\".format(name)), sep=\" \", index_col=0)\n",
    "    if -1 in df or -2 in df or -3 in df:\n",
    "        print(\"Some folds were not computed\")\n",
    "    res_index = df.index\n",
    "    res_index = res_index.append(sorct_df.index)\n",
    "    result_df = pd.DataFrame(index=res_index)\n",
    "    \n",
    "    \n",
    "    for cl_name in res_index:\n",
    "        \n",
    "        \n",
    "        n_invalid = 0\n",
    "        n_invalid_sorct = 0\n",
    "        time = 0\n",
    "        hlr_time = 0\n",
    "        iters = 0\n",
    "        hlr_score = 0\n",
    "        sorct_score = 0\n",
    "        hs = 0\n",
    "        cp = 0\n",
    "        sorct_train_score = 0\n",
    "        hlr_train_score = 0\n",
    "        # sorct no init values\n",
    "        no_init_time = 0\n",
    "        no_init_iters = 0\n",
    "        no_init_score = 0\n",
    "        no_init_train_score = 0\n",
    "        for fold_index in range(N_FOLDS):\n",
    "            if cl_name != \"SORCT\":\n",
    "                if df.loc[cl_name,\"Time_{}\".format(fold_index)] < 0:\n",
    "                    print( df.loc[cl_name,\"Time_{}\".format(fold_index)])\n",
    "                    n_invalid += 1\n",
    "                    print(df.loc[cl_name,\"Time_{}\".format(fold_index)])\n",
    "                else:\n",
    "                    time += df.loc[cl_name,\"Time_{}\".format(fold_index)]\n",
    "                    if not IGNORE_HLR_TIME:\n",
    "                        hlr_time += df.loc[cl_name, \"HLR_Time_{}\".format(fold_index)]\n",
    "                    iters += df.loc[cl_name, \"Iterations_{}\".format(fold_index)]\n",
    "                    hlr_score += df.loc[cl_name, \"HLR_Score_{}\".format(fold_index)]\n",
    "                    sorct_score += df.loc[cl_name, \"SORCT_Score_{}\".format(fold_index)]\n",
    "                    hs += df.loc[cl_name, \"Homogeneity_{}\".format(fold_index)]\n",
    "                    cp += df.loc[cl_name, \"Completeness_{}\".format(fold_index)]\n",
    "                    sorct_train_score += df.loc[cl_name, \"SORCT_Score_Train_{}\".format(fold_index)]\n",
    "                    hlr_train_score += df.loc[cl_name, \"HLR_Score_Train_{}\".format(fold_index)]\n",
    "            # else sorct no init\n",
    "            else:\n",
    "                if  sorct_df.loc[\"SORCT\", \"Time_{}\".format(fold_index) ] < 0:\n",
    "                    n_invalid_sorct +=1\n",
    "                else:\n",
    "                    no_init_time += sorct_df.loc[\"SORCT\", \"Time_{}\".format(fold_index) ]\n",
    "                    no_init_iters +=  sorct_df.loc[\"SORCT\", \"Iterations_{}\".format(fold_index) ]\n",
    "                    no_init_score +=  sorct_df.loc[\"SORCT\", \"Score_{}\".format(fold_index) ]\n",
    "                    no_init_train_score += sorct_df.loc[\"SORCT\", \"Score_Train_{}\".format(fold_index) ]\n",
    "        if cl_name != \"SORCT\":\n",
    "            real_folds = N_FOLDS - n_invalid\n",
    "            time = time / real_folds\n",
    "            hlr_time = hlr_time / real_folds\n",
    "            iters = iters / real_folds\n",
    "            hlr_score = hlr_score / real_folds\n",
    "            sorct_score = sorct_score / real_folds\n",
    "            hs = hs / real_folds\n",
    "            cp = cp / real_folds\n",
    "            sorct_train_score = sorct_train_score / real_folds\n",
    "            hlr_train_score = hlr_train_score / real_folds\n",
    "            result_df.loc[cl_name, \"Time\"] = time\n",
    "            if not IGNORE_HLR_TIME:\n",
    "                result_df.loc[cl_name, \"HLR_Time\"] = hlr_time\n",
    "            result_df.loc[cl_name, \"Iterations\"] = iters\n",
    "            result_df.loc[cl_name, \"Train_HLR_Score\"] = hlr_train_score\n",
    "            result_df.loc[cl_name, \"Train_SORCT_Score\"] = sorct_train_score\n",
    "            result_df.loc[cl_name, \"HLR_Score\"] = hlr_score\n",
    "            result_df.loc[cl_name, \"SORCT_Score\"] = sorct_score\n",
    "            result_df.loc[cl_name, \"Homogeneity\"] = hs\n",
    "            result_df.loc[cl_name, \"Completeness\"] = cp\n",
    "            result_df.loc[cl_name, \"Invalid Folds\"] = n_invalid \n",
    "        else:\n",
    "            n_folds_reals = N_FOLDS - n_invalid_sorct\n",
    "            result_df.loc[cl_name, \"Invalid Folds\"] = n_invalid_sorct \n",
    "            result_df.loc[cl_name, \"Time\"] = no_init_time / n_folds_reals\n",
    "            result_df.loc[cl_name, \"Iterations\"] = no_init_iters / n_folds_reals\n",
    "            result_df.loc[cl_name, \"SORCT_Score\"] = no_init_score / n_folds_reals\n",
    "            result_df.loc[cl_name, \"Train_SORCT_Score\"] = no_init_train_score / n_folds_reals\n",
    "\n",
    "    #result_df[\"Invalid Folds\"] = result_df[\"Invalid Folds\"].astype(\"int32\")\n",
    "    dfs.append(result_df)\n",
    "    result_df.to_csv(os.path.join(res_path, \"{}_final.csv\".format(name)), float_format='%.2f')\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2df9d0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Train_HLR_Score</th>\n",
       "      <th>Train_SORCT_Score</th>\n",
       "      <th>HLR_Score</th>\n",
       "      <th>SORCT_Score</th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Invalid Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kmeans</th>\n",
       "      <td>248.518142</td>\n",
       "      <td>1243.40</td>\n",
       "      <td>0.753853</td>\n",
       "      <td>0.548790</td>\n",
       "      <td>0.747187</td>\n",
       "      <td>0.516185</td>\n",
       "      <td>0.136548</td>\n",
       "      <td>0.082333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agglomerative_sigle</th>\n",
       "      <td>103.241131</td>\n",
       "      <td>542.40</td>\n",
       "      <td>0.753853</td>\n",
       "      <td>0.660848</td>\n",
       "      <td>0.747187</td>\n",
       "      <td>0.624833</td>\n",
       "      <td>0.155252</td>\n",
       "      <td>0.093587</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birch</th>\n",
       "      <td>128.442929</td>\n",
       "      <td>697.25</td>\n",
       "      <td>0.742930</td>\n",
       "      <td>0.624195</td>\n",
       "      <td>0.746546</td>\n",
       "      <td>0.560545</td>\n",
       "      <td>0.138434</td>\n",
       "      <td>0.090244</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_labels</th>\n",
       "      <td>141.129395</td>\n",
       "      <td>755.00</td>\n",
       "      <td>0.753853</td>\n",
       "      <td>0.655119</td>\n",
       "      <td>0.747187</td>\n",
       "      <td>0.616114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SORCT</th>\n",
       "      <td>127.013860</td>\n",
       "      <td>703.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.565029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Time  Iterations  Train_HLR_Score  \\\n",
       "kmeans               248.518142     1243.40         0.753853   \n",
       "Agglomerative_sigle  103.241131      542.40         0.753853   \n",
       "birch                128.442929      697.25         0.742930   \n",
       "True_labels          141.129395      755.00         0.753853   \n",
       "SORCT                127.013860      703.80              NaN   \n",
       "\n",
       "                     Train_SORCT_Score  HLR_Score  SORCT_Score  Homogeneity  \\\n",
       "kmeans                        0.548790   0.747187     0.516185     0.136548   \n",
       "Agglomerative_sigle           0.660848   0.747187     0.624833     0.155252   \n",
       "birch                         0.624195   0.746546     0.560545     0.138434   \n",
       "True_labels                   0.655119   0.747187     0.616114     1.000000   \n",
       "SORCT                         0.565029        NaN     0.540438          NaN   \n",
       "\n",
       "                     Completeness  Invalid Folds  \n",
       "kmeans                   0.082333            0.0  \n",
       "Agglomerative_sigle      0.093587            0.0  \n",
       "birch                    0.090244            1.0  \n",
       "True_labels              1.000000            0.0  \n",
       "SORCT                         NaN            0.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a259b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37794/2369220504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SORCT_Score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SORCT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    index = list(df.index)\n",
    "    fig, ax = plt.subplots()\n",
    "    values = df[\"SORCT_Score\"]\n",
    "    values = values/values.loc[\"SORCT\"]\n",
    "    ax.bar(index, values)\n",
    "    ax.set_ylim([0.8,1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    index = list(df.index)\n",
    "    fig, ax = plt.subplots()\n",
    "    values = df[\"Time\"]\n",
    "    values = values/values.loc[\"SORCT\"]\n",
    "    ax.bar(index, values)\n",
    "    ax.set_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35aadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    index = list(df.index)\n",
    "    fig, ax = plt.subplots()\n",
    "    values = df[\"Iterations\"]\n",
    "    values = values/values.loc[\"SORCT\"]\n",
    "    ax.bar(index, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be9eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac36cb",
   "metadata": {},
   "source": [
    "## Test train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_list = [\"car\", \"iris\",\"new_thyroid\", \"seeds_data\", \"splice\"]\n",
    "N_SPLITS = 5\n",
    "OPT_TYPE = \"simple\"\n",
    "SEED = 1234\n",
    "for dataset_name in dataset_name_list:\n",
    "    if dataset_name == \"iris\":\n",
    "        X, y = datasets.load_iris(as_frame=True, return_X_y=True)\n",
    "        df = pd.DataFrame(X)\n",
    "        df[\"Classes\"] = y\n",
    "    elif dataset_name == \"car\":\n",
    "        dataset_path = os.path.join(\"datasets\", \"{}.csv\".format(dataset_name))\n",
    "        df = pd.read_csv(dataset_path, delimiter=\";\", header=0)\n",
    "        df = df.convert_dtypes()\n",
    "        # dictionary converting ordinal categories to values\n",
    "        cost_dict = {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3}\n",
    "        doors_dict = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
    "        persons_dict = {\"2\": 2, \"4\": 4, \"more\": 5}\n",
    "        dimension_dict = {\"small\": 0, \"med\": 1, \"big\": 2}\n",
    "        # buying\n",
    "        df[\"buying\"] = df[\"buying\"].apply(lambda x: cost_dict[x])\n",
    "        df[\"maint\"] = df[\"maint\"].apply(lambda x: cost_dict[x])\n",
    "        df[\"doors\"] = df[\"doors\"].apply(lambda x: doors_dict[x])\n",
    "        df[\"persons\"] = df[\"persons\"].apply(lambda x: persons_dict[x])\n",
    "        df[\"lug_boot\"] = df[\"lug_boot\"].apply(lambda x: dimension_dict[x])\n",
    "        df[\"safety\"] = df[\"safety\"].apply(lambda x: cost_dict[x])\n",
    "        classes_encoder = preprocessing.LabelEncoder().fit(df[\"Classes\"])\n",
    "        df[\"Classes\"] = classes_encoder.transform(df[\"Classes\"])\n",
    "    else:\n",
    "        dataset_path = os.path.join(\"datasets\", \"{}.csv\".format(dataset_name))\n",
    "        df = pd.read_csv(dataset_path, delimiter=\";\", header=0)\n",
    "    if \"Id\" in df:\n",
    "        df = df.drop('Id', axis=1)\n",
    "    df_std = df.copy()\n",
    "    scaler = MinMaxScaler()  # also MaxAbsScaler()\n",
    "    # Preprocessing: we get the columns names of features which have to be standardized\n",
    "    columns_names = list(df)\n",
    "    index_features = list(range(0, len(df_std.columns) - 1))\n",
    "    # The name of the classes K\n",
    "    classes = df_std['Classes'].unique().tolist()\n",
    "    classes_en = [i for i in range(len(classes))]\n",
    "    # Encoder processing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df_std['Classes'])\n",
    "    df_std['Classes'] = le.transform(df_std['Classes'])\n",
    "    # Scaling phase\n",
    "    df_std[columns_names[0:-1]] = scaler.fit_transform(df_std[columns_names[0:-1]])\n",
    "    for column in columns_names[0:-1]:\n",
    "        # TODO janky solution to unreliable MinMaxScaler behaviour\n",
    "        df_std.loc[df[column] > 1, column] = 1\n",
    "        df_std.loc[df[column] < 0, column] = 0\n",
    "\n",
    "    X = df_std[columns_names[:-1]]\n",
    "    y = df_std[columns_names[-1]]\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    n_leaves = 4\n",
    "    fold_index = 0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        print(\"Fold\", fold_index)\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        df_train = pd.concat([X_train, y_train], axis=1)\n",
    "        df_test = pd.concat([X_test, y_test], axis=1)\n",
    "        # sample weightingsorct_iters\n",
    "        occurences = [len(y_train[y_train == x]) for x in classes]\n",
    "        total_samples = sum(occurences)\n",
    "        sample_weight = np.zeros_like(y_train)\n",
    "        for class_index, n_occurr in zip(classes, occurences):\n",
    "            sample_weight[y_train == class_index] = n_occurr\n",
    "        sample_weight = sample_weight / total_samples\n",
    "        #HLR_car_Agglomerative_sigle_0.pkl\n",
    "        # HLR\n",
    "        # true labels\n",
    "        filename = \"HLR_{}_{}_{}.pkl\".format(\"tl\",dataset_name, fold_index)\n",
    "        with open(os.path.join(\"results\", filename), \"rb\") as f:\n",
    "            hlr = pickle.load(f)\n",
    "        run_tests.create_model()\n",
    "        \n",
    "        fold_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf42baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/SORCT_new_thyroid_birch_4.pkl\", \"rb\") as f:\n",
    "    roba = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "roba.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08590ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "roba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641189ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e26bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = pd.DataFrame(index=[\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.loc[\"a\",\"culo\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.loc[\"d\", \"culo\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.index.append([\"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17605ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cc0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\"datasets\", \"car.csv\")\n",
    "df = pd.read_csv(dataset_path, delimiter=\";\", header=0)\n",
    "df = df.convert_dtypes()\n",
    "# dictionary converting ordinal categories to values\n",
    "cost_dict = {\"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3}\n",
    "doors_dict = {\"2\": 2, \"3\": 3, \"4\": 4, \"5more\": 5}\n",
    "persons_dict = {\"2\": 2, \"4\": 4, \"more\": 5}\n",
    "dimension_dict = {\"small\": 0, \"med\": 1, \"big\": 2}\n",
    "# buying\n",
    "df[\"buying\"] = df[\"buying\"].apply(lambda x: cost_dict[x])\n",
    "df[\"maint\"] = df[\"maint\"].apply(lambda x: cost_dict[x])\n",
    "df[\"doors\"] = df[\"doors\"].apply(lambda x: doors_dict[x])\n",
    "df[\"persons\"] = df[\"persons\"].apply(lambda x: persons_dict[x])\n",
    "df[\"lug_boot\"] = df[\"lug_boot\"].apply(lambda x: dimension_dict[x])\n",
    "df[\"safety\"] = df[\"safety\"].apply(lambda x: cost_dict[x])\n",
    "classes_encoder = preprocessing.LabelEncoder().fit(df[\"Classes\"])\n",
    "df[\"Classes\"] = classes_encoder.transform(df[\"Classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d249b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,    2,    3,    5,    6,    7,    8,    9,   10,   12,\n",
       "            ...\n",
       "            1715, 1716, 1717, 1718, 1719, 1720, 1722, 1724, 1725, 1726],\n",
       "           dtype='int64', length=1296)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_SPLITS = 4\n",
    "SEED = 1234\n",
    "n_feature = len(df.columns)-1\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "X = df[df.columns[0:n_feature]]\n",
    "y = df[\"Classes\"]\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    df_test = pd.concat([X_test, y_test], axis=1)\n",
    "    train_index = df_train.index\n",
    "    break\n",
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381ba696",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"HLR_tl_car_0.pkl\"\n",
    "with open(os.path.join(\"results\", filename), \"rb\") as f:\n",
    "    hlr_dict = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f206f7c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37794/2405037766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOPT_TYPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"simple\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhlr_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPT_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhlr_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_projects/optimization-project/train_test.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(init, opt_tipe, df_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_tipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mI_in_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Classes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSORCT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_in_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI_in_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mI_in_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classes_en' is not defined"
     ]
    }
   ],
   "source": [
    "OPT_TYPE = \"simple\"\n",
    "init  = train_test.get_model_init(hlr_dict, range(0,6), train_index, [0,1,2])\n",
    "model = train_test.create_model(init, OPT_TYPE, df_train)\n",
    "hlr_score = train_test.predict(model, X_train, y_train, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095ab00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees",
   "language": "python",
   "name": "decision_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
