{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ddc090",
   "metadata": {},
   "source": [
    "# Thyroid Dataset\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b211819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c61774",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "name = \"seeds_data.csv\"\n",
    "DATASET_PATH = os.path.join(\"datasets\", name)\n",
    "df = pd.read_csv(DATASET_PATH, delimiter=\";\", header=0)\n",
    "columns = list(df.columns)\n",
    "X = df[columns[:-1]]\n",
    "y = df[columns[-1]]\n",
    "feature_names = columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0fe97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 210\n",
      "Shape: (210, 8)\n",
      "The are 8 columns\n",
      "\n",
      "Distinct values for 'Classes' column\n",
      "1    70\n",
      "2    70\n",
      "3    70\n",
      "Name: Classes, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows: {}\\nShape: {}\".format(len(df), df.shape))\n",
    "print(\"The are {} columns\".format(len(df.columns)))\n",
    "print(\"\\nDistinct values for 'Classes' column\\n{}\\n\".format(df[\"Classes\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9851dd4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = y.unique()\n",
    "vals.sort()\n",
    "heights = [len(y[y==x]) for x in vals ]\n",
    "vals = [str(x) for x in vals]\n",
    "plt.bar(vals, heights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd1127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2beb1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = X.copy()\n",
    "X_std[feature_names] = StandardScaler().fit_transform(X[feature_names])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.25, random_state=SEED)\n",
    "classes = y.unique().tolist()\n",
    "classes.sort() # sorted   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c8d45",
   "metadata": {},
   "source": [
    "Sample weigthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f423c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = [len(y_train[y_train==x]) for x in classes]\n",
    "total_samples = sum(occurences)\n",
    "sample_weight = np.zeros_like(y_train)\n",
    "for class_index, n_occurr in zip(classes, occurences):\n",
    "    sample_weight[y_train==class_index]=n_occurr\n",
    "sample_weight = sample_weight/total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b26b60",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85bf520",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_leaves = 4\n",
    "n_clusters = n_leaves\n",
    "clustering_estimators = []\n",
    "params = dict(n_clusters=n_clusters, random_state=SEED)\n",
    "kmeans = KMeans(**params)\n",
    "clustering_estimators.append(kmeans)\n",
    "\n",
    "# Spectral clustering not used since it gave looped\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"single\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"ward\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"complete\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"average\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters)\n",
    "birch = Birch(**params)\n",
    "clustering_estimators.append(birch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383d5bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans 0.7261283679366535\n",
      "AgglomerativeClustering 0.01859330194315294\n",
      "AgglomerativeClustering 0.7986888162083502\n",
      "AgglomerativeClustering 0.7141741988641893\n",
      "AgglomerativeClustering 0.7907534575132681\n",
      "Birch 0.6901918780485845\n",
      "The best estimator is AgglomerativeClustering(n_clusters=4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarpindaro/miniconda3/envs/decision_trees/lib/python3.9/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but Birch was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import find_best_estimator\n",
    "\n",
    "for i in range(len(clustering_estimators)):\n",
    "    try:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train, sample_weight=sample_weight.transpose())\n",
    "    except:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train)\n",
    "\n",
    "for estimator in clustering_estimators:\n",
    "    print(estimator.__class__.__name__, homogeneity_score(y_train, estimator.labels_))\n",
    "    \n",
    "best_estimator = find_best_estimator(clustering_estimators, homogeneity_score, y_train)\n",
    "print(\"The best estimator is {}\".format(best_estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bac9d9",
   "metadata": {},
   "source": [
    "## Leaves assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27467e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the estimator KMeans, the assignment [0, 2, 1, 3] has a score of 0.7595795340741557\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 2, 1, 3] has a score of 0.1946292848707431\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 2, 1, 3] has a score of 0.8331515577888864\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 2, 1, 3] has a score of 0.8331515577888864\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 1, 2, 3] has a score of 0.7168116778969846\n",
      "For the estimator Birch, the assignment [0, 2, 1, 3] has a score of 0.8051919914849429\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import best_leaf_assignment\n",
    "for estimator in clustering_estimators:\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "    print(\"For the estimator {}, the assignment {} has a score of {}\".format(estimator.__class__.__name__,\n",
    "                                                                             assignment, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e710b",
   "metadata": {},
   "source": [
    "## Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b72a0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cluster import HierarchicalLogisticRegression\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)), n_leaves=n_leaves, prediction_type=\"deterministic\", random_state=0,\n",
    "                                     logistic_params={\"class_weight\": \"balanced\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a63a92e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(n_clusters=4, random_state=1234) accuracy:0.5849056603773585\n",
      "AgglomerativeClustering(linkage='single', n_clusters=4) accuracy:0.03773584905660377\n",
      "AgglomerativeClustering(n_clusters=4) accuracy:0.03773584905660377\n",
      "AgglomerativeClustering(linkage='complete', n_clusters=4) accuracy:0.03773584905660377\n",
      "AgglomerativeClustering(linkage='average', n_clusters=4) accuracy:0.3584905660377358\n",
      "Birch(n_clusters=4) accuracy:0.03773584905660377\n",
      "\n",
      "The best was KMeans(n_clusters=4, random_state=1234) with score 0.5849056603773585\n"
     ]
    }
   ],
   "source": [
    "best = clustering_estimators[0]\n",
    "best_accuracy = 0\n",
    "i = 0\n",
    "for estimator in clustering_estimators:\n",
    "    \"\"\"\n",
    "    print(estimator)\n",
    "    print(np.unique(estimator.labels_))\n",
    "    for un in np.unique(estimator.labels_):\n",
    "        print(len(estimator.labels_[estimator.labels_==un]))\n",
    "    \"\"\"\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                  true_labels=y_train, metric=completeness_score)\n",
    "    HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=estimator.labels_, leaves_assignment=assignment)\n",
    "    accuracy = HLR.score(X_test.to_numpy(), y_test)\n",
    "    print(\"{} accuracy:{}\".format(estimator, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best = clustering_estimators[i]\n",
    "        best_accuracy = accuracy\n",
    "    i +=1\n",
    "print(\"\\nThe best was {} with score {}\".format(best, best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d749ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true labelling has assignment [0, 3, 1, 2] with score 1.0000000000000009\n",
      "Accuracy using true labellling: 0.5471698113207547\n"
     ]
    }
   ],
   "source": [
    "assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=y_train, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "print(\"The true labelling has assignment {} with score {}\".format(assignment, score))\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)),\n",
    "                                     n_leaves=n_leaves, prediction_type=\"deterministic\",\n",
    "                                     random_state=0)\n",
    "HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=y_train, leaves_assignment=assignment)\n",
    "accuracy = HLR.score(X_test.to_numpy(), y_test)\n",
    "print(\"Accuracy using true labellling: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15286a85",
   "metadata": {},
   "source": [
    "In this notebook there is the only case in which a clustrering algorithm performs better than the true labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439c647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees",
   "language": "python",
   "name": "decision_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
