{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8717ef5a",
   "metadata": {},
   "source": [
    "# Thyroid Dataset\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169f98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from src.ORCTModel import ORCTModel, predicted_lab, accuracy\n",
    "from src.cluster import HierarchicalLogisticRegression, best_leaf_assignment\n",
    "\n",
    "import operator\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c14f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "name = \"new_thyroid.csv\"\n",
    "DATASET_PATH = os.path.join(\"datasets\", name)\n",
    "df = pd.read_csv(DATASET_PATH, delimiter=\";\", header=0)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "columns = list(df.columns)\n",
    "X = df[columns[:-1]]\n",
    "y = df[columns[-1]]\n",
    "feature_names = columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f471f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3771\n",
      "Shape: (3771, 22)\n",
      "The are 22 columns\n",
      "\n",
      "Distinct values for 'Classes' column\n",
      "2    3487\n",
      "1     191\n",
      "0      93\n",
      "Name: Classes, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows: {}\\nShape: {}\".format(len(df), df.shape))\n",
    "print(\"The are {} columns\".format(len(df.columns)))\n",
    "print(\"\\nDistinct values for 'Classes' column\\n{}\\n\".format(df[\"Classes\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2c93d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = y.unique()\n",
    "vals.sort()\n",
    "heights = [len(y[y==x]) for x in vals ]\n",
    "vals = [str(x) for x in vals]\n",
    "plt.bar(vals, heights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e1e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = X.copy()\n",
    "X_std[feature_names] = MinMaxScaler().fit_transform(X[feature_names])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.25, random_state=SEED)\n",
    "index_features = list(range(0, len(feature_names) - 1))\n",
    "index_instances = list(X_train.index)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "classes = y.unique().tolist()\n",
    "classes.sort() # sorted    \n",
    "classes_en = [i for i in range(len(classes))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89490a7",
   "metadata": {},
   "source": [
    "Sample weigthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630a5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = [len(y_train[y_train==x]) for x in classes]\n",
    "total_samples = sum(occurences)\n",
    "sample_weight = np.zeros_like(y_train)\n",
    "for class_index, n_occurr in zip(classes, occurences):\n",
    "    sample_weight[y_train==class_index]=n_occurr\n",
    "sample_weight = sample_weight/total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcd321",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0040ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_leaves = 4\n",
    "n_clusters = n_leaves\n",
    "clustering_estimators = []\n",
    "params = dict(n_clusters=n_clusters, random_state=SEED)\n",
    "kmeans = KMeans(**params)\n",
    "clustering_estimators.append(kmeans)\n",
    "\n",
    "# Spectral clustering not used since it gave looped\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"single\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"ward\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"complete\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"average\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters)\n",
    "birch = Birch(**params)\n",
    "clustering_estimators.append(birch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05bec3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans 0.03071630923835349\n",
      "AgglomerativeClustering 0.0002648202557415631\n",
      "AgglomerativeClustering 0.027214759684686778\n",
      "AgglomerativeClustering 0.005515461053430391\n",
      "AgglomerativeClustering 0.007174716837755318\n",
      "Birch 0.01720381013165665\n",
      "The best estimator is KMeans(n_clusters=4, random_state=1234)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarpindaro/miniconda3/envs/decision_trees/lib/python3.9/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but Birch was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import find_best_estimator\n",
    "\n",
    "for i in range(len(clustering_estimators)):\n",
    "    try:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train, sample_weight=sample_weight.transpose())\n",
    "    except:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train)\n",
    "\n",
    "for estimator in clustering_estimators:\n",
    "    print(estimator.__class__.__name__, homogeneity_score(y_train, estimator.labels_))\n",
    "    \n",
    "best_estimator = find_best_estimator(clustering_estimators, homogeneity_score, y_train)\n",
    "print(\"The best estimator is {}\".format(best_estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef0fcd",
   "metadata": {},
   "source": [
    "## Leaves assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fc0591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the estimator KMeans, the assignment [0, 3, 1, 2] has a score of 0.008101878533974389\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 3, 1, 2] has a score of 0.009629814142041693\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 2, 1, 3] has a score of 0.007623468537665565\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 3, 1, 2] has a score of 0.004451263856176911\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 1, 2, 3] has a score of 0.07395048274034136\n",
      "For the estimator Birch, the assignment [0, 2, 1, 3] has a score of 0.009227622508936797\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import best_leaf_assignment\n",
    "for estimator in clustering_estimators:\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "    print(\"For the estimator {}, the assignment {} has a score of {}\".format(estimator.__class__.__name__,\n",
    "                                                                             assignment, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd1ccd",
   "metadata": {},
   "source": [
    "## Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc0e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cluster import HierarchicalLogisticRegression\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)), n_leaves=n_leaves, prediction_type=\"deterministic\", random_state=0,\n",
    "                                     logistic_params={\"class_weight\": \"balanced\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b9f8e",
   "metadata": {},
   "source": [
    "The clustering algorithm behave like random classifiers. In this case, since there is a strong imbalance, *balanced_accuracy_score* is used to computed the real accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c827029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(n_clusters=4, random_state=1234) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='single', n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='complete', n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='average', n_clusters=4) accuracy:0.1693292806484296\n",
      "Birch(n_clusters=4) accuracy:0.3333333333333333\n",
      "The best was KMeans(n_clusters=4, random_state=1234) with score 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "best = clustering_estimators[0]\n",
    "best_accuracy = 0\n",
    "i = 0\n",
    "for estimator in clustering_estimators:\n",
    "    \"\"\"\n",
    "    print(estimator)\n",
    "    print(np.unique(estimator.labels_))\n",
    "    for un in np.unique(estimator.labels_):\n",
    "        print(len(estimator.labels_[estimator.labels_==un]))\n",
    "    \"\"\"\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                  true_labels=y_train, metric=completeness_score)\n",
    "    HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=estimator.labels_, leaves_assignment=assignment )\n",
    "    accuracy = balanced_accuracy_score( y_test, HLR.predict(X_test.to_numpy()))\n",
    "    print(\"{} accuracy:{}\".format(estimator, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best = clustering_estimators[i]\n",
    "        best_accuracy = accuracy\n",
    "    i +=1\n",
    "print(\"The best was {} with score {}\".format(best, best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "053037f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true labelling has assignment [0, 2, 1, 3] with score 1.0000000000000042\n",
      "Accuracy using true labellling: 0.3650793650793651\n"
     ]
    }
   ],
   "source": [
    "assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=y_train, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "print(\"The true labelling has assignment {} with score {}\".format(assignment, score))\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)),\n",
    "                                     n_leaves=n_leaves, prediction_type=\"deterministic\",\n",
    "                                     random_state=0)\n",
    "HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=y_train, leaves_assignment=assignment)\n",
    "accuracy = balanced_accuracy_score( y_test, HLR.predict(X_test.to_numpy()))\n",
    "print(\"Accuracy using true labellling: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f80e0",
   "metadata": {},
   "source": [
    "## ORCT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_in_NR(model, i):\n",
    "    if i == 4:\n",
    "        return []\n",
    "    elif i == 5:\n",
    "        return [2]\n",
    "    elif i == 6:\n",
    "        return [1]\n",
    "    elif i == 7:\n",
    "        return [1, 3]\n",
    "\n",
    "\n",
    "def B_in_NL(model, i):\n",
    "    if i == 4:\n",
    "        return [1, 2]\n",
    "    elif i == 5:\n",
    "        return [1]\n",
    "    elif i == 6:\n",
    "        return [3]\n",
    "    elif i == 7:\n",
    "        return []\n",
    "\n",
    "\n",
    "def I_k(model, i):\n",
    "    if i == 0:\n",
    "        return I_in_k[0]\n",
    "    elif i == 1:\n",
    "        return I_in_k[1]\n",
    "    elif i == 2:\n",
    "        return I_in_k[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce22c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_in_NL_R = {4: [], 5: [2], 6: [1], 7: [1, 3]}\n",
    "BF_in_NL_L = {4: [1, 2], 5: [1], 6: [3], 7: []}\n",
    "I_in_k = {i: list(df_train[df_train['Classes'] == i].index) for i in range(len(classes))}\n",
    "my_W = {(i, j): 0.5 if i != j else 0 for i in classes_en for j in classes_en}\n",
    "index_instances = list(X_train.index)\n",
    "my_x = {(i, j): df_train.loc[i][j] for i in index_instances for j in index_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1541edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.stack(HLR.coef_).transpose()\n",
    "mu = np.stack(HLR.intercept_)\n",
    "C = HLR.leaf_class_probs_.transpose()\n",
    "# j+1 due to the convention for the branch nodes (numbered from 1)\n",
    "# it's in the form\n",
    "# (0,1) (0,2) (0,3)\n",
    "# (1,1) (1,2) (1,3) and so one\n",
    "init_a = {(i, j + 1): a[i, j] for i in range(len(index_features)) for j in range(3)}\n",
    "# in the form (1) (2) (3)\n",
    "init_mu = {(i + 1): mu[i] for i in range(3)}\n",
    "# shape (n_classes, n_leaves), and leaves are the last 4 numbers of 2^h -1\n",
    "# (0,4) (0,5) (0,6) (0,7)\n",
    "# (1,4) ---\n",
    "init_c = {(i, j + 4): C[i, j] for i in classes_en for j in range(4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26d1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Initializing ordered Set I with a fundamentally unordered data source\n",
      "    (type: set).  This WILL potentially lead to nondeterministic behavior in\n",
      "    Pyomo\n",
      "WARNING: Initializing ordered Set N_B with a fundamentally unordered data\n",
      "    source (type: set).  This WILL potentially lead to nondeterministic\n",
      "    behavior in Pyomo\n"
     ]
    }
   ],
   "source": [
    "model = ORCTModel(I_in_k=I_in_k, I_k_fun=I_k, index_features=index_features, BF_in_NL_R=BF_in_NL_R,\n",
    "                      B_in_NR=B_in_NR, B_in_NL=B_in_NL, error_weights=my_W, x_train=my_x, init_a=init_a,\n",
    "                      init_mu=init_mu, init_C=init_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d647e8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.12.13: \n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.12.13, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:    99390\n",
      "Number of nonzeros in inequality constraint Jacobian.:      252\n",
      "Number of nonzeros in Lagrangian Hessian.............:    28829\n",
      "\n",
      "Error in an AMPL evaluation. Run with \"halt_on_ampl_error yes\" to see details.\n",
      "Error evaluating Jacobian of equality constraints at user provided starting point.\n",
      "  No scaling factors for equality constraints computed!\n",
      "Error in an AMPL evaluation. Run with \"halt_on_ampl_error yes\" to see details.\n",
      "\n",
      "Number of Iterations....: 0\n",
      "\n",
      "Number of objective function evaluations             = 0\n",
      "Number of objective gradient evaluations             = 0\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 1\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.092\n",
      "Total CPU secs in NLP function evaluations           =      0.007\n",
      "\n",
      "EXIT: Invalid number in NLP function or derivative detected.\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot load a SolverResults object with bad status: error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11025/261960248.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mipopt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"~/miniconda3/envs/decision_trees/bin/ipopt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipopt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git_projects/optimization-project/src/ORCTModel.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, exec_path)\u001b[0m\n\u001b[1;32m     76\u001b[0m         opt = SolverFactory('ipopt',\n\u001b[1;32m     77\u001b[0m                             executable=exec_path)  # in executable the directory path of ipopt.exe\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtee\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/opt/base/solvers.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_solutions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                         _model.solutions.load_from(\n\u001b[0m\u001b[1;32m    627\u001b[0m                             \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                             \u001b[0mselect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision_trees/lib/python3.9/site-packages/pyomo/core/base/PyomoModel.py\u001b[0m in \u001b[0;36mload_from\u001b[0;34m(self, results, allow_consistent_values_for_fixed_vars, comparison_tolerance_for_fixed_vars, ignore_invalid_labels, id, delete_symbol_map, clear, default_variable_value, select, ignore_fixed_vars)\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \"an 'aborted' status, but containing a solution\")\n\u001b[1;32m    223\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 raise ValueError(\"Cannot load a SolverResults object \"\n\u001b[0m\u001b[1;32m    225\u001b[0m                                  \u001b[0;34m\"with bad status: %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                                  % str(results.solver.status))\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load a SolverResults object with bad status: error"
     ]
    }
   ],
   "source": [
    "ipopt_path = \"~/miniconda3/envs/decision_trees/bin/ipopt\"\n",
    "model.solve(ipopt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fcf106",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model.extraction_va()\n",
    "\n",
    "\n",
    "labels = predicted_lab(model.model, X_test, val, index_features)\n",
    "a = accuracy(y_test.to_numpy(), labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees",
   "language": "python",
   "name": "decision_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
