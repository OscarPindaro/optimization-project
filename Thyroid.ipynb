{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8717ef5a",
   "metadata": {},
   "source": [
    "# Thyroid Dataset\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169f98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, Birch\n",
    "from sklearn.metrics import completeness_score, homogeneity_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from pyomo.environ import *\n",
    "from pyomo.opt import SolverFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c14f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "name = \"new_thyroid.csv\"\n",
    "DATASET_PATH = os.path.join(\"datasets\", name)\n",
    "df = pd.read_csv(DATASET_PATH, delimiter=\";\", header=0)\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "columns = list(df.columns)\n",
    "X = df[columns[:-1]]\n",
    "y = df[columns[-1]]\n",
    "feature_names = columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f471f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3771\n",
      "Shape: (3771, 22)\n",
      "The are 22 columns\n",
      "\n",
      "Distinct values for 'Classes' column\n",
      "2    3487\n",
      "1     191\n",
      "0      93\n",
      "Name: Classes, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows: {}\\nShape: {}\".format(len(df), df.shape))\n",
    "print(\"The are {} columns\".format(len(df.columns)))\n",
    "print(\"\\nDistinct values for 'Classes' column\\n{}\\n\".format(df[\"Classes\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2c93d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = y.unique()\n",
    "vals.sort()\n",
    "heights = [len(y[y==x]) for x in vals ]\n",
    "vals = [str(x) for x in vals]\n",
    "plt.bar(vals, heights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e1e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = X.copy()\n",
    "X_std[feature_names] = StandardScaler().fit_transform(X[feature_names])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.25, random_state=SEED)\n",
    "classes = y.unique().tolist()\n",
    "classes.sort() # sorted    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89490a7",
   "metadata": {},
   "source": [
    "Sample weigthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "630a5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = [len(y_train[y_train==x]) for x in classes]\n",
    "total_samples = sum(occurences)\n",
    "sample_weight = np.zeros_like(y_train)\n",
    "for class_index, n_occurr in zip(classes, occurences):\n",
    "    sample_weight[y_train==class_index]=n_occurr\n",
    "sample_weight = sample_weight/total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcd321",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0040ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_leaves = 4\n",
    "n_clusters = n_leaves\n",
    "clustering_estimators = []\n",
    "params = dict(n_clusters=n_clusters, random_state=SEED)\n",
    "kmeans = KMeans(**params)\n",
    "clustering_estimators.append(kmeans)\n",
    "\n",
    "# Spectral clustering not used since it gave looped\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"single\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"ward\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"complete\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters, linkage=\"average\")\n",
    "agglomerate = AgglomerativeClustering(**params)\n",
    "clustering_estimators.append(agglomerate)\n",
    "\n",
    "params = dict(n_clusters=n_clusters)\n",
    "birch = Birch(**params)\n",
    "clustering_estimators.append(birch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05bec3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans 0.003812165228867576\n",
      "AgglomerativeClustering 0.002917711285713676\n",
      "AgglomerativeClustering 0.0035271417996518956\n",
      "AgglomerativeClustering 0.01694657897191726\n",
      "AgglomerativeClustering 0.017003825453331373\n",
      "Birch 0.0008901905382124796\n",
      "The best estimator is AgglomerativeClustering(linkage='average', n_clusters=4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarpindaro/miniconda3/envs/decision_trees/lib/python3.9/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but Birch was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import find_best_estimator\n",
    "\n",
    "for i in range(len(clustering_estimators)):\n",
    "    try:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train, sample_weight=sample_weight.transpose())\n",
    "    except:\n",
    "        clustering_estimators[i] = clustering_estimators[i].fit(X_train)\n",
    "\n",
    "for estimator in clustering_estimators:\n",
    "    print(estimator.__class__.__name__, homogeneity_score(y_train, estimator.labels_))\n",
    "    \n",
    "best_estimator = find_best_estimator(clustering_estimators, homogeneity_score, y_train)\n",
    "print(\"The best estimator is {}\".format(best_estimator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef0fcd",
   "metadata": {},
   "source": [
    "## Leaves assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78fc0591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the estimator KMeans, the assignment [0, 3, 1, 2] has a score of 0.01500974149773457\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 2, 1, 3] has a score of 0.014141170188801415\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 2, 1, 3] has a score of 0.011167881833673541\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 1, 2, 3] has a score of 0.337169669437351\n",
      "For the estimator AgglomerativeClustering, the assignment [0, 1, 2, 3] has a score of 0.337169669437351\n",
      "For the estimator Birch, the assignment [0, 1, 2, 3] has a score of 0.004313518149861123\n"
     ]
    }
   ],
   "source": [
    "from src.cluster import best_leaf_assignment\n",
    "for estimator in clustering_estimators:\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "    print(\"For the estimator {}, the assignment {} has a score of {}\".format(estimator.__class__.__name__,\n",
    "                                                                             assignment, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd1ccd",
   "metadata": {},
   "source": [
    "## Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc0e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cluster import HierarchicalLogisticRegression\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)), n_leaves=n_leaves, prediction_type=\"deterministic\", random_state=0,\n",
    "                                     logistic_params={\"class_weight\": \"balanced\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b9f8e",
   "metadata": {},
   "source": [
    "The clustering algorithm behave like random classifiers. In this case, since there is a strong imbalance, *balanced_accuracy_score* is used to computed the real accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c827029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(n_clusters=4, random_state=1234) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='single', n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(n_clusters=4) accuracy:0.3333333333333333\n",
      "AgglomerativeClustering(linkage='complete', n_clusters=4) accuracy:0.03212698412698412\n",
      "AgglomerativeClustering(linkage='average', n_clusters=4) accuracy:0.03212698412698412\n",
      "Birch(n_clusters=4) accuracy:0.3333333333333333\n",
      "The best was KMeans(n_clusters=4, random_state=1234) with score 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "best = clustering_estimators[0]\n",
    "best_accuracy = 0\n",
    "i = 0\n",
    "for estimator in clustering_estimators:\n",
    "    \"\"\"\n",
    "    print(estimator)\n",
    "    print(np.unique(estimator.labels_))\n",
    "    for un in np.unique(estimator.labels_):\n",
    "        print(len(estimator.labels_[estimator.labels_==un]))\n",
    "    \"\"\"\n",
    "    assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=estimator.labels_, \n",
    "                                  true_labels=y_train, metric=completeness_score)\n",
    "    HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=estimator.labels_, leaves_assignment=assignment )\n",
    "    accuracy = balanced_accuracy_score( y_test, HLR.predict(X_test.to_numpy()))\n",
    "    print(\"{} accuracy:{}\".format(estimator, accuracy))\n",
    "    if accuracy > best_accuracy:\n",
    "        best = clustering_estimators[i]\n",
    "        best_accuracy = accuracy\n",
    "    i +=1\n",
    "print(\"The best was {} with score {}\".format(best, best_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "053037f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true labelling has assignment [0, 2, 1, 3] with score 1.0000000000000042\n",
      "Accuracy using true labellling: 0.5861587301587301\n"
     ]
    }
   ],
   "source": [
    "assignment, score = best_leaf_assignment(n_leaves=n_leaves, estimated_labels=y_train, \n",
    "                                      true_labels=y_train, metric=completeness_score)\n",
    "print(\"The true labelling has assignment {} with score {}\".format(assignment, score))\n",
    "HLR = HierarchicalLogisticRegression(n_classes=len(np.unique(y_train)),\n",
    "                                     n_leaves=n_leaves, prediction_type=\"deterministic\",\n",
    "                                     random_state=0)\n",
    "HLR = HLR.fit(X_train.to_numpy(), y_train, cluster_labels=y_train, leaves_assignment=assignment)\n",
    "accuracy = balanced_accuracy_score( y_test, HLR.predict(X_test.to_numpy()))\n",
    "print(\"Accuracy using true labellling: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65575b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_trees",
   "language": "python",
   "name": "decision_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
